<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-09-14T23:35:46+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Mihály Koltai</title><subtitle>[&quot;personal website&quot;]</subtitle><entry><title type="html">Testing grids in Markdown</title><link href="http://localhost:4000/test/" rel="alternate" type="text/html" title="Testing grids in Markdown" /><published>2024-09-05T00:00:00+01:00</published><updated>2024-09-05T00:00:00+01:00</updated><id>http://localhost:4000/test</id><content type="html" xml:base="http://localhost:4000/test/"><![CDATA[<p>this is a test</p>

<html lang="en">
<head>
    <style>
        .grid-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
            margin: 20px 0;
        }
        .grid-item {
            background-color: #f0f0f0;
            padding: 20px;
            text-align: center;
            border-radius: 8px;
            box-shadow: 2px 2px 12px rgba(0, 0, 0, 0.1);
        }
        a {
            text-decoration: none;
            color: #0073e6;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>

<div class="grid-container">
    <div class="grid-item">
        <a href="https://your-link1.com">Section 1</a>
    </div>
    <div class="grid-item">
        <a href="https://your-link2.com">Section 2</a>
    </div>
    <div class="grid-item">
        <a href="https://your-link3.com">Section 3</a>
    </div>
    <div class="grid-item">
        <a href="https://your-link4.com">Section 4</a>
    </div>
</div>

</body>
</html>]]></content><author><name></name></author><category term="tools" /><category term="github-blog" /><summary type="html"><![CDATA[no serious content here]]></summary></entry><entry><title type="html">Erosion of the FIDESZ vote share in the EP2024 elections - on the brink?</title><link href="http://localhost:4000/ep2024-hungary-datavis/" rel="alternate" type="text/html" title="Erosion of the FIDESZ vote share in the EP2024 elections - on the brink?" /><published>2024-08-10T00:00:00+01:00</published><updated>2024-08-10T00:00:00+01:00</updated><id>http://localhost:4000/ep2024-hungary-datavis</id><content type="html" xml:base="http://localhost:4000/ep2024-hungary-datavis/"><![CDATA[<p>[This is a post about Hungarian politics.]</p>

<p>For the first time in a decade in Hungary, the governing FIDESZ-KDNP party (from here: FIDESZ/the government) saw its vote share fall substantially in the 2024 European Parliament elections (EP2024). There were a range of opinions how bad the results were for FIDESZ, if at all, and what the results portend for the 2026 national elections.
Below, I present a number of graphs exploring how much the share and number of votes for FIDESZ changed compared to the last European elections, across different geographies in the country. Finally, I map the results onto parliamentary constituencies and analyse what they could mean in a national election.</p>

<ol>
  <li><a href="#results-national level">Results at the national level</a></li>
  <li><a href="#results-by-individual-towns-and-cities">Results by individual towns and cities</a></li>
  <li><a href="#results-aggregated-by-settlement-types">Results aggregated by settlement types</a></li>
  <li><a href="#results-by-parliamentary-constituencies">Results by parliamentary constituencies</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ol>

<h3 id="results-at-the-national-level"><ins>Results at the national level</ins></h3>

<p>How did the government party perform on the elections on the national level?
Figure 1 shows both the share and number of votes cast for FIDESZ, the (non-far-right) opposition bloc and the far-right Mi Hazánk party. I included in the opposition all parties that are explicitly or plausibly in favour of a change of government and that are not to the right of FIDESZ. I also removed business parties and some minor party only running in 2019 (Munkaspart).
This then includes within the opposition the following parties EP2019 and EP2024:</p>
<ul>
  <li>DK/MSZP/Parbeszed (either separate or in coalition)</li>
  <li>Jobbik</li>
  <li>LMP</li>
  <li>MMN (Mindenki Magyarországa Néppárt; only running in 2024)</li>
  <li>Momentum</li>
  <li>TISZA Part (only running in 2024)</li>
</ul>

<p>The results are summarised in Figure 1 below.</p>

<!--- $$ \delta GDP =  \delta pop + \delta GDPpp + \delta pop \times \delta GDPpp \approx \delta pop + \delta GDPpp
\tag{3}\label{eq3}$$ -->
<!--- REFERENCE. \ref{eq3}  -->

<p><img src="/images/ep2024/FIDESZ_ellenzek_Mihaz_EP_2019_2024_orsz.png" alt="_config.yml" /></p>
<h4 id="figure-1-national-level-results-of-the-2019-and-2024-ep-elections-in-absolute-numbers-thousands-and-percentages-all-non-far-right-opposition-parties-were-grouped-in-one-column-full-resol">Figure 1: National level results of the 2019 and 2024 EP elections, in absolute numbers (thousands) and percentages. All non-far-right opposition parties were grouped in one column <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/FIDESZ_ellenzek_Mihaz_EP_2019_2024_orsz.png">[<ins>full resol.</ins>]</a></h4>

<p>In 2019 FIDESZ had an absolute majority nationally at 52.6% of the vote, which fell to below 45% (44.8%) in the EP2024. Some commentators argued that these are still good results for the government because in absolute terms they went up, not down.
This is true, in that the FIDESZ voting bloc expanded from 1.82 million to 2.05 million. However, this increase of approximately 200 thousand votes was outdone by the opposition’s 680 thousand vote bump, an almost 3.5x larger increase.<br />
This resulted in the combined opposition vote reaching 48.1% nationally, exceeding FIDESZ by about 150 thousand votes, or 3.3% of (valid) ballots cast. That the <em>non-far-right</em> opposition’s (defining Jobbik as far-right 2008-2018 and Mi Hazánk since its inception) vote share were larger than (or equal to) FIDESZ’s last happened in the 2006 general elections. In fact, in all three EP elections since 2009 FIDESZ had more than half of the national vote, just as it did in all general elections since 2010, except in 2014 (technically 49.3% in 2018).<br />
Another notable development from 2019 to 2024 are the gains by the Mi Hazánk party, doubling their vote share to 6.7%, by 192 thousand votes.</p>

<p>How did this \(\approx\)8% slump in the Fidesz vote share come about geographically?</p>

<h3 id="results-by-individual-towns-and-cities"><ins>Results by individual towns and cities</ins></h3>

<p>To analyse changes of the electoral map, I grouped all settlements, towns and cities into the following groups, by the number of <em>eligible voters</em> (ie. these numbers are adults only, which is \(\approx\)80% of the total population):</p>
<ul>
  <li>villages with less than 1000 voters</li>
  <li>villages/small towns with 1000 to 5000 voters</li>
  <li>small towns with 5000 to 10,000 voters</li>
  <li>towns/smaller cities with 10,000 to 20,000 voters</li>
  <li>smaller/medium cities with 20,000 to 40,000 voters</li>
  <li>cities with 40,000 to 70,000 voters</li>
  <li>large cities with more than 70,000 voters</li>
  <li>Budapest districts</li>
</ul>

<p>Figure 2 shows how the vote share of FIDESZ changed from EP2019 to 2024 across all these geographies. The blue colour shows a <em>fall</em> in the government vote share, whereas red (using red here instead of orange because of its better visibility) shows those settlements/towns/cities where its vote share went up.</p>

<p><img src="/images/ep2024/indiv_telep/FIDESZKDNP_szazalek_szint_2019_2024_indiv_telep.png" alt="_config.yml" /></p>
<h4 id="figure-2-fidesz-vote-share-in-2019-and-2024-arrowhead2024-base2019-in-all-settlements-of-hungary-blue-color-shows-a-fall-in-the-vote-share-full-resol">Figure 2: FIDESZ vote share in 2019 and 2024 (arrowhead=2024, base=2019) in all settlements of Hungary. Blue color shows a fall in the vote share <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/indiv_telep/FIDESZKDNP_szazalek_szint_2019_2024_indiv_telep.png">[<ins>full resol.</ins>]</a></h4>

<p>The FIDESZ vote share went down in every town/city with more than 10 thousand voters, with the single exception of Ózd.
To see the extent of the change in the vote share, Figure 3 shows only the percentage difference between EP2019 and 2024.
Even among towns of 5 to 10 thousand voters there are only two where the government vote share increased (Nagyatád, Tiszavasvári); and not very many small towns of 1 to 5 thousand where it did either (93 out of 943 towns).
The government vote share fell typically by 5-10% in larger towns and cities, but in smaller towns of 1 to 10 thousand voters often by even more.</p>

<p><img src="/images/ep2024/indiv_telep/FIDESZKDNP_szazalek_valtozas_2019_2024_indiv_telep.png" alt="_config.yml" /></p>
<h4 id="figure-3-fidesz-vote-share-in-2019-and-2024-in-all-settlements-of-hungary-02019-result-blue-color-shows-a-fall-in-the-vote-share-full-resol">Figure 3: FIDESZ vote share in 2019 and 2024 in all settlements of Hungary (0=2019 result). Blue color shows a fall in the vote share <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/indiv_telep/FIDESZKDNP_szazalek_valtozas_2019_2024_indiv_telep.png">[<ins>full resol.</ins>]</a></h4>

<p>On Figure 2 it is also apparent that among towns with &lt;20 thousand voters FIDESZ still had an absolute majority. The colour coding in Figure 4 shows the towns/cities where the government vote share was still above 50% in 2024 (shown in red).</p>

<p><img src="/images/ep2024/indiv_telep/FIDESZKDNP_szazalek_szint_2019_2024_indiv_telep_colorcode_absztobbs.png" alt="_config.yml" /></p>
<h4 id="figure-4-fidesz-vote-share-in-2019-to-2024-arrowhead2024-base2019-in-all-settlements-of-hungary-blue-color-shows-vote-share-in-2024-under-50-red-above-50-full-resol">Figure 4: FIDESZ vote share in 2019 to 2024 (arrowhead=2024, base=2019) in all settlements of Hungary. Blue color shows vote share in 2024 under 50%, red above 50% <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/indiv_telep/FIDESZKDNP_szazalek_szint_2019_2024_indiv_telep_colorcode_absztobbs.png">[<ins>full resol.</ins>]</a></h4>

<p>There were no towns/cities in EP2024 with more than 20 thousand voters where FIDESZ received more than 50% of the vote. The largest towns where they still have an absolute majority are ones with 10-20 thousand voters.</p>

<p>What will decide parliamentary constituencies is the <em>difference</em> between the government and the opposition voting blocs. Figure 5 shows how the FIDESZ vs. opposition vote share <em>difference</em> changed from 2019 to 2024 (positive values meaning a larger percentage of votes for FIDESZ). In red color are those settlements where FIDESZ still maintained an advantage over the opposition voting bloc. There were only three cities with 20+ thousand voters where this was the case (Ózd, Kiskunhalas, Zalagerszeg [with a tiny difference]). Major cities with previously large FIDESZ majorities such as Debrecen, Győr, Kecskemét, Szombathely, Sopron, Kaposvár had in 2024 more people voting for (non-far-right) opposition parties than for the government. In already opposition-majority areas like Budapest, Szeged, Pécs the opposition bloc’s edge over the government increased further.<br />
On the other hand, in towns/villages with less than 5 thousand voters FIDESZ still mostly dominated, whereas in the medium range of towns with 5 to 20 thousand voters it is a mix.</p>

<p><img src="/images/ep2024/indiv_telep/fideszellenzek_2019_2024_valtozas_szazalekkulonb_indiv_telep_colorcode_fideszelony.png" alt="_config.yml" /></p>
<h4 id="figure-5-difference-between-the-fidesz-vote-share-and-that-of-the-opposition-in-2019-and-2024-arrowhead2024-base2019-blue-color-shows-the-opposition-getting-more-votes-in-2024-than-fidesz-negative-value-means-the-opposition-had-a-higher-vote-share-than-fidesz-full-resol">Figure 5: difference between the FIDESZ vote share and that of the opposition in 2019 and 2024 (arrowhead=2024, base=2019). Blue color shows the opposition getting more votes in 2024 than FIDESZ. Negative value means the opposition had a higher vote share than FIDESZ <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/indiv_telep/fideszellenzek_2019_2024_valtozas_szazalekkulonb_indiv_telep_colorcode_fideszelony.png">[<ins>full resol.</ins>]</a></h4>

<p>Even in smaller towns of 1 to 10 thousand voters most of the arrows seem to point leftward, meaning a shrinking FIDESZ advantage (red arrows in Figure 5) or towns tipping over to the opposition (blue arrows in Figure 5).</p>

<p>Figure 6 shows the same results by colour coding the results by the <em>direction</em> of the change.</p>

<p><img src="/images/ep2024/indiv_telep/fideszellenzek_2019_2024_valtozas_szazalekkulonb_indiv_telep.png" alt="_config.yml" /></p>
<h4 id="figure-6-difference-between-the-fidesz-vote-share-and-that-of-the-opposition-in-2019-and-2024-arrowhead2024-base2019-blue-color-shows-the-opposition-improving-its-result-since-2019-against-fidesz-negative-value-means-the-opposition-had-a-higher-vote-share-than-fidesz-full-resol">Figure 6: difference between the FIDESZ vote share and that of the opposition in 2019 and 2024 (arrowhead=2024, base=2019). Blue color shows the opposition improving its result since 2019 against FIDESZ. Negative value means the opposition had a higher vote share than FIDESZ <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/indiv_telep/fideszellenzek_2019_2024_valtozas_szazalekkulonb_indiv_telep.png">[<ins>full resol.</ins>]</a></h4>

<p>There are only three towns/cities over 10 thousand where FIDESZ improved its result <em>compared to the opposition</em> (Ózd, Komlo, Oroszlany), and even in 5-10 thousand towns only four. There were numerous villages on the other hand where FIDESZ managed to do this.</p>

<p>Next I summarise these shifts by aggregating results of individual towns by these categories.</p>

<!--hello $$\label{hellolabel}$$REF $$\ref{hellolabel}$$-->

<h3 id="results-aggregated-by-settlement-types"><ins>Results aggregated by settlement types</ins></h3>

<p>Figure 7 shows results if we aggregate them from individual settlements, again grouping them by number of voters. The total number of votes increased from 2019 to 2024, on the national level going from 3.41 to 4.57 million. Of this 1.16 million increase approximately 680 thousand went to the non-far-right opposition, 220 thousand to FIDESZ and 190 thousand to Mi Hazánk.</p>

<p>However, these shifts looked very different at the level of different geographies. In absolute number of votes FIDESZ stood still (or marginally went down) in Budapest, and towns/cities with more than 5000 voters. As the opposition managed to increase its vote numbers this meant falling vote shares for FIDESZ, now going below 50% in all categories above the 5000 voter threshold, and falling below 40% in the category of 40+ thousand cities, where the opposition voting bloc went over 50%.
In the category of towns with 5 to 10 thousand voters FIDESZ still maintained a thin relative majority, while it still maintains an absolute majority in the category of &lt;5 thousand towns and villages. The FIDESZ mobilisation seemed to have worked only in this latter small town/village category, though interestingly it coincided with a comparable mobilisation of opposition voters as well.</p>

<p><img src="/images/ep2024/aggreg_telep_tipus/fidesz_ellenzek_2019_2024_aggreg_nvalpolg_kateg.png" alt="_config.yml" /></p>
<h4 id="figure-7-vote-share-and-number-of-votes-for-fidesz-and-the-opposition-in-2019-and-2024-arrowhead2024-base2019-by-settlement-type-full-resol">Figure 7: Vote share and number of votes for FIDESZ and the opposition in 2019 and 2024 (arrowhead=2024, base=2019), by settlement type. <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/aggreg_telep_tipus/fidesz_ellenzek_2019_2024_aggreg_nvalpolg_kateg.png">[<ins>full resol.</ins>]</a></h4>

<p>Figure 8 shows only the <em>changes</em> in the absolute and relative size of voting blocs, also showing the far-right Mi Hazánk increasing both its vote tally and vote share (+3-4%) across all categories.</p>

<p><img src="/images/ep2024/aggreg_telep_tipus/fidesz_ellenzek_mihazank_2019_2024_valtozas_aggreg_nvalpolg_kateg.png" alt="_config.yml" /></p>
<h4 id="figure-8-change-in-the-vote-share-and-number-of-votes-for-fidesz-and-the-opposition-in-2019-and-2024-02019-result-by-settlement-type-full-resol">Figure 8: Change in the vote share and number of votes for FIDESZ and the opposition in 2019 and 2024 (0=2019 result), by settlement type. <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/aggreg_telep_tipus/fidesz_ellenzek_mihazank_2019_2024_valtozas_aggreg_nvalpolg_kateg.png">[<ins>full resol.</ins>]</a></h4>

<p>We can also observe that the FIDESZ vote share fell by 6 to 10% across the board, while the non-far-right opposition’s went up by 2 to 5%.</p>

<p>It is also interesting to look at the <em>number</em> of settlements where there is a government or opposition majority, shown on Figure 9.</p>

<p><img src="/images/ep2024/aggreg_telep_tipus/fidesz_ellenzek_aggreg_nvalpolg_kateg_krit_ntelep.png" alt="_config.yml" /></p>
<h4 id="figure-9-number-of-settlements-where-1-fidesz-got-more-votes-than-the-opposition-in-2019-and-2024-arrowhead-2-fidesz-received-more-than-50-of-the-vote-in-2019-arrow-base-and-2024-arrowhead-3-the-difference-in-vote-share-between-fidesz-and-the-opposition-went-down-opposition-improved-its-result-from-2019-to-2024-4-fidesz-vote-share-went-down-from-2019-to-2024-panels-correspond-to-settlements-within-a-given-settlement-category-number-of-voters-full-resol">Figure 9: Number of settlements where 1) FIDESZ got more votes than the opposition in 2019 and 2024 (arrowhead) 2) FIDESZ received more than 50% of the vote in 2019 (arrow base) and 2024 (arrowhead) 3) the difference in vote share between FIDESZ and the opposition went down (opposition improved its result) from 2019 to 2024 4) FIDESZ vote share went down from 2019 to 2024. Panels correspond to settlements within a given settlement category (number of voters) <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/aggreg_telep_tipus/fidesz_ellenzek_aggreg_nvalpolg_kateg_krit_ntelep.png">[<ins>full resol.</ins>]</a></h4>

<p>Among settlements with more than 20 thousand voters (including Budapest districts), there were none in 2024 with a FIDESZ absolute majority and only three with a relative FIDESZ majority. In 17/59 towns with 10 to 20 thousand voters, FIDESZ still maintained a relative majority (8/59 absolute).
Going down by population size we have a growing proportion of towns with a relative (absolute) FIDESZ majority, becoming overwhelming in villages:</p>
<ul>
  <li>5 to 10 thousand voters: 64 out of 111 (38/111)</li>
  <li>1 to 5 thousand voters: 749 out of 943 (558/943)</li>
  <li>less than 1 thousand voters: 1787 out of 1995 (1570/1995)</li>
</ul>

<p>The number of settlements with either a relative or absolute government majority went down in every category.</p>

<p>The main question is: how would these results convert into parliamentary constituencies?</p>

<h3 id="results-by-parliamentary-constituencies"><ins>Results by parliamentary constituencies</ins></h3>

<p>There are 106 parliamentary constituencies (OEVK) in Hungary. I mapped the above results from individual settlements onto these 106 electoral districts, shown on Figure 10.  I took the non-far-right opposition parties as one block and calculated the percentage <em>difference</em> between the FIDESZ and opposition voting blocs, with the colour coding showing districts going for FIDESZ (orange) or the opposition (blue).</p>

<p><img src="/images/ep2024/OEVK_fidesz_ellenzek_szazalek kulonbs.png" alt="_config.yml" /></p>
<h4 id="figure-10-ep2024-results-mapped-onto-parliamentary-constituencies-oevk-showing-the-percentage-difference-numbers-in-parenthesis-positive-values-are-fidesz-majorities-between-fidesz-and-opposition-votes-orange-circles-show-fidesz-majorities-blue-ones-opposition-full-resol">Figure 10: EP2024 results mapped onto parliamentary constituencies (OEVK), showing the percentage difference (numbers in parenthesis, positive values are FIDESZ majorities) between FIDESZ and opposition votes. Orange circles show FIDESZ majorities, blue ones opposition. <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/OEVK_fidesz_ellenzek_szazalek kulonbs.png">[<ins>full resol.</ins>]</a></h4>

<p>With the proportions of the EP2024 all Budapest parliamentary districts had opposition majorities, along with most of Pest county. The picture varies in the other counties, with city-dominated districts having strong opposition majorities, and vice versa for village-dominated districts.</p>

<p>This is however assuming that the opposition block will indeed be one bloc, ie. the opposition will field a single candidate in every parliamentary constituency. Even if the FIDESZ vs opposition proportions of EP2024 were to hold, this is a (very) optimistic assumption from the point of view of the opposition, that might well not be true in 2026. So what level of integration would the opposition need to get this result, and what number of constituencies would they get at different levels of integration/splintering? This is what is shown on Figure 11, with the x-axis showing the percentage of EP2024 votes for the opposition going for a single candidate and the y-axis the resulting number of constituencies for the two blocs.</p>

<p><img src="/images/ep2024/OEVK_fidesz_ellenzek_scan.png" alt="_config.yml" /></p>
<h4 id="figure-11-constituencies-gained-by-fidesz-vs-the-opposition-as-a-function-of-the--of-the-opposition-vote-in-ep2024-going-for-a-single-candidate-full-resol">Figure 11: constituencies gained by FIDESZ vs the opposition as a function of the % of the opposition vote in EP2024 going for a single candidate <a href="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/ep2024/OEVK_fidesz_ellenzek_scan.png">[<ins>full resol.</ins>]</a></h4>

<p>If the opposition were to field a single candidate everywhere <em>and</em> retain all its EP2024 votes, it could win a slim majority of constituencies, 54 vs 52. The largest opposition party in the 2024 elections, TISZA, received \(\approx\)65% of the opposition vote. With this level of integration FIDESZ could still win about 4/5th of constituencies, despite receiving 150 thousand (3.3% of the total) less votes than the non-far-right opposition.</p>

<h3 id="conclusion"><ins>Conclusion</ins></h3>

<p>The above is only a numerical and visual analysis, not a political one. It analyses the results in 2024 and when it maps them onto parliamentary constituencies to make a projection (not a prediction) it assumes that the proportions of the EP2024 would hold.
In reality, this latter assumption is unlikely be true, as the political situation in Hungary is very volatile and both the government and the main opposition party will try hard to shift the balance. Nevertheless, what the analysis shows is that while FIDESZ suffered a substantial erosion of its voting bloc, even with this result, it would easily win a parliamentary election if the opposition voting bloc is <em>at all</em> splintered. Even if the main opposition party managed to absorb the entire non-far-right voting bloc <em>and</em> the EP2024 proportions were to hold, it could get only a slim majority of parliamentary constituencies.<br />
The Hungarian electoral system is two-tier, and another 93 seats will be allocated through the national list, where FIDESZ usually gets another 200-250 thousand votes from Hungarians living in neighbouring countries. This would effectively wipe out the 3% edge that the opposition had nationally at EP2024. This in turn would mean a roughly equal number of seats from the national list for the two blocs, but also 5-8 seats for the Mi Hazánk party if they clear the 5% threshold, as they did in 2024. So the EP2024 results, even assuming <em>complete</em> integration of the opposition voting bloc, could well end up in a hung parliament, with Mi Hazánk potentially in a kingmaker position.
Since the numbers will likely change, it makes no sense to dwell more on the numerical projections. The main unknown of the EP2024 election is where one million FIDESZ voters from the 2022 general election (GE2022) disappeared. Of course this was an EP rather than a general election, but the (pro)government media machinery switched to its highest gear with its ‘anti-war’ campaign to turn out the base. Despite this, while 3.06 million people voted for FIDESZ in the GE2022, this fell to 2.05 million in EP2024. Meanwhile, compared to the GE2022, the opposition managed to marginally increase its vote tally by 66 thousand.</p>

<p>The main question is if the one million ‘disappeared’ FIDESZ voters can be re-mobilised by the government for the GE2026. If to a large extent yes, then they would almost certainly win in 2026. If not, or only in small part, then the question in turn would be if the opposition reached its upper limit in EP2024 or there is a reservoir of voters who did not turn out in 2024 but could in 2026 <em>or</em> there are GE2022 FIDESZ voters that it could win over. The analysis above suggests that for the opposition to win, it would likely need more voters than the 2.2 million it had in EP2024, because even in the best case (zero loss of opposition votes due to competing candidates), the EP2024 result would only be enough for a hung parliament or a razor thin majority.<br />
The town- and constituency-level analysis above suggests what could be districts where FIDESZ is particularly vulnerable, having thin majorities and having suffered major losses compared to its previous results. Whether the opposition will be able to exploit that remains to be seen.</p>

<p><ins>Source code</ins><br />
Source code and data files for plots at <a href="https://github.com/mbkoltai/EP_valasztasok">Github repo</a>.</p>]]></content><author><name></name></author><category term="politics" /><category term="hungary" /><category term="elections" /><category term="data-visualisation" /><summary type="html"><![CDATA[Getting closer, but not enough yet]]></summary></entry><entry><title type="html">Sources of economic growth in the US, UK, Germany &amp;amp; Japan, 1990-2019</title><link href="http://localhost:4000/decomposing-gdp-growth/" rel="alternate" type="text/html" title="Sources of economic growth in the US, UK, Germany &amp;amp; Japan, 1990-2019" /><published>2022-10-29T00:00:00+01:00</published><updated>2022-10-29T00:00:00+01:00</updated><id>http://localhost:4000/decomposing-gdp-growth</id><content type="html" xml:base="http://localhost:4000/decomposing-gdp-growth/"><![CDATA[<p>There has been much talk recently about the low growth rate in the UK economy since 2008 and how it must be increased. Often the discussion is about GDP growth, although some commentators also referred to the underlying measure of GDP <em>per capita</em> (or output per capita) as the more relevant metric to look at.
GDP and its growth is a composite measure, because it is an outcome of (growth in) the size of the population, the number of people at work and labour productivity (output per hour).
GDP growth can be decomposed to its components by a linear approximation. We can look at GDP growth as a result of GDP/capita and population growth or decompose it further into employment growth, growth in the annual workload and labour productivity. To make a comparison, I did this decomposition for four major high-income econonomies below, the US, UK, Germany and Japan.</p>

<ol>
  <li><a href="#population-vs-productivity-growth">Population vs productivity growth</a></li>
  <li><a href="#employment-vs-productivity-growth">Employment vs productivity growth</a></li>
</ol>

<h3 id="population-vs-productivity-growth"><ins>Population vs productivity growth</ins></h3>

<p>We can define GDP as a product of population size (<em>pop</em>) and GDP per person (\(GDPpp\)):</p>

\[GDP = GDPpp \times population
\tag{1}\label{eq1}\]

<p>Then, the change in GDP from year <em>t</em>  to <em>t+1</em> (\(\Delta GDP\)) can be expressed as:</p>

\[\Delta GDP = (GDPpp_t + \Delta GDPpp) \times (pop_t + \Delta pop) - GDPpp_t \times pop_t = \\
GDPpp_t \times \Delta pop + \Delta GDPpp \times pop_t + \Delta GDPpp \Delta pop
\tag{2}\label{eq2}\]

<p>Dividing through by \(GDPpp_t \times pop_t\) to calculate the change as a fraction (\(\delta\)) of the base year <em>t</em>:</p>

\[\delta GDP =  \delta pop + \delta GDPpp + \delta pop \times \delta GDPpp \approx \delta pop + \delta GDPpp
\tag{3}\label{eq3}\]

<p>Where we dropped the \(\delta pop \times \delta GDPpp\) as this is a product of fractional terms, therefore quite small.
This means that the percentage change in GDP can be approximated as the sum of the percentage change in population size and GDP per capita. In other words we can separate how much of economic growth is due to population growth and how much to an increasing output per capita. While a growing population increases economic output in absolute terms it does not (in itself) increase output per person which is more relevant if we want to discuss whether a country is growing richer as well.</p>

<p>I tested how well this linear decomposition (Eq. \ref{eq3}) can explain GDP growth in four major high-income economies, the US, the UK, Germany and Japan.</p>

<!---
$$GDP = population \times GDP/capita \\
\% \ GDP \ growth \approx \% \ population \ growth + \% \ GDP\ per \ capita \ growth
\tag{1}\label{gdp_popul}$$  
 -->

<!--- [around 3.5%](https://www.imf.org/en/Publications/WEO/Issues/2021/01/26/2021-world-economic-outlook-update) -->
<!---GDP growth data vs its linear decomposition: -->

<p><img src="/images/growth_comps/gdp_growth_comps_decompos_comparison.png" alt="_config.yml" /></p>

<p>There is good correspondence visually and calculating correlations confirms that this linear decomposition can explain more than 90% of GDP growth data:</p>

<p><img src="/images/growth_comps/corr_table.png" alt="_config.yml" /></p>

<p>We now want to calculate how much of GDP growth can be accounted for by population growth vs per capita output growth in these four countries. I calculated the mean growth rates of GDP, population and GDP per capita for three periods: 1990-2000, 2001-2008 and 2009-2019, corresponding to the three business cycles of the last three decades and leaving out recession years that would distort the calculation.</p>

<p>We can first look at the mean growth rates in absolute terms:
<img src="/images/growth_comps/DEU_GBR_USA_JPN_growth_comps_popul_gdppercap_mean.png" alt="_config.yml" /></p>

<p>There is a slowdown of GDP growth in all four countries, but the composition of growth also changes for the US and the UK. While for Japan and Germany almost all growth comes from GDP per capita, in the US and the UK population growth also contributes substantially. In the case of the UK the share of GDP growth coming from population growth increased as well.</p>

<p>We can see this better if we plot the average of the ratio of population growth and GDP per capita growth to GDP growth (x100):</p>

<p><img src="/images/growth_comps/DEU_GBR_USA_JPN_growth_comps_popul_gdppercap_mean_share_gdp.png" alt="_config.yml" /></p>

<p>Now we can see more clearly that whereas almost all GDP growth can be explained by increasing GDP/capita in Japan and Germany, in the US 30-40% of GDP growth comes from population growth on average in all three periods. In the UK the share of population growth in economic growth increased substantially, from around 10% to above 30%. In contrast, population growth has been a drag on economic growth in Japan as the population started to shrink recently.</p>

<p>There are two issues with this decomposition. First, GDP per capita is still a composite measure, as it depends on several underlying variables: on the number of people working and output per worker in its numerator but also on population in its denominator. Therefore it could be increasing or decreasing for different reasons. This is particularly relevant for Japan where the population decreased recently. Second, total population is not the direct source of economic growth, as from the point of view of value production it is the working population that is relevant. Therefore we need to decompose GDP growth into its more elementary components.</p>

<h3 id="employment-vs-productivity-growth"><ins>Employment vs productivity growth</ins></h3>

<p>GDP can be described as a product of 1) the number of people at work (employment; E) 2) hours worked per year per worker (AHW) 3) output per hour of work (labour productivity, LP):</p>

<p>\(GDP = employment  \times (annual  \ working  \ hours) \times (output \ per \ hour) = E \times HW \times LP\)
<!--- \% \ GDP \ growth \approx \%  \ employment \ growth + \% \ growth  \ work \ hours + \% \ growth \ output \ per \ hour
\tag{2}\label{gdp_employ} ---></p>

<p>Applying the same logic as in Eq. \ref{eq3} we can derive the fractional change in GDP, again dropping second and third order terms:
\(\delta GDP \approx \delta E + \delta AHW + \delta LP
\tag{4}\label{eq4}\)</p>

<p>In other words, we are now asking how much of GDP growth came from:</p>
<ul>
  <li>more people working</li>
  <li>people working more</li>
  <li>labour becoming more productive</li>
</ul>

<p>First, we calculate the average growth rates for GDP and its three components:</p>

<p><img src="/images/growth_comps/DEU_GBR_USA_JPN_growth_comps_mean.png" alt="_config.yml" /></p>

<p>Annual work hours had a negative effect on growth in all three periods in Germany and Japan, because the number of hours people work fell. While this was also true in the US and UK before the financial crisis, since 2009 work hours had a small positive contribution in these two countries.
In Japan labour productivity was the leading source of growth in each period, whereas in Germany this was true before 2000, but since then growth in employment has been equally important. In the US and UK growth in employment had a larger and growing share in economic growth and it became the main source of it following the financial crisis, surpassing labour productivity, which had the weakest growth in the UK.</p>

<p>Let’s again plot the relative share of these components in GDP growth as well:</p>

<p><img src="/images/growth_comps/DEU_GBR_USA_JPN_growth_comps_mean_share_gdp.png" alt="_config.yml" /></p>

<p>In summary, approximately 60% of economic growth in the UK post-2008 was due to more people at work, and not an increase in output per worker. The latter is arguably a better measure of wealth and technological progress.
In discussions of how to increase the rate of economic growth - if that is desirable and possible at all, something I did not discuss here - it would be helpful to separate its components as analysed above, not to mix up the expansion of the labour force (mainly due to immigration) with work actually becoming more productive. <br />
<br />
<ins>Source code</ins><br />
Source code and data files for plots at <a href="https://github.com/mbkoltai/gdp-growth-decomp">Github repo</a>.</p>]]></content><author><name></name></author><category term="political-economy" /><category term="globalization" /><category term="growth" /><category term="gdp" /><summary type="html"><![CDATA[Labour force expansion vs. productivity growth]]></summary></entry><entry><title type="html">The COVID-19 crash and future scenarios</title><link href="http://localhost:4000/covid-crash-recovery/" rel="alternate" type="text/html" title="The COVID-19 crash and future scenarios" /><published>2021-07-19T00:00:00+01:00</published><updated>2021-07-19T00:00:00+01:00</updated><id>http://localhost:4000/covid-crash-recovery</id><content type="html" xml:base="http://localhost:4000/covid-crash-recovery/"><![CDATA[<ol>
  <li><a href="#crash">Crash</a></li>
  <li><a href="#response">Response</a></li>
  <li><a href="#pandemic-prospects">Pandemic prospects</a></li>
  <li><a href="#recovery">Recovery</a></li>
  <li><a href="#what-about-globalisation">What about globalisation?</a></li>
</ol>

<p>Last February-March I wrote a <a href="https://mbkoltai.github.io/illusion-globalisation/">post</a> on whether the shock of the pandemic could unravel the whole system of globalisation. From long-term estimates of economic growth I tried to show that the globalisation of the last 30-40 years was on a different scale than previous cycles of expansion of global trade and finance.
Since this burst-like expansion of global trade and finance coincided with a similar growth of private and public debt, I speculated if the system could be more fragile than expected and might start to disintegrate as the pandemic hits it on a systemic level, not isolated to certain sectors or regions like in previous crises of the last decades. This disintegration has so far not happened. Before going into the reasons why, let’s look at the scale of economic fallout from the pandemic and how governments reacted in response.</p>

<h3 id="crash"><ins>Crash</ins></h3>

<p>The world economy shrank by <a href="https://www.imf.org/en/Publications/WEO/Issues/2021/01/26/2021-world-economic-outlook-update">around 3.5%</a> in 2020 while world trade fell <a href="https://unctad.org/system/files/official-document/ditcinf2021d1_en.pdf">by 9%</a>.
This is slightly worse than in 2009 for GDP (<a href="https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG">-1.7%</a>), but less severe for world trade which fell by
<a href="https://policyoptions.irpp.org/magazines/g8g20/the-great-recession-and-international-trade/">12%</a> in 2009.
Whatever the exact numbers are, the headline figures for 2009 and 2020 are comparable.<br />
Business as usual? In a sense it is still early days since a process of disintegration would take longer to work its way through the world economy. But for the moment a general de-globalisation does not seem to be happening, in fact some countries have already <a href="https://policyoptions.irpp.org/magazines/g8g20/the-great-recession-and-international-trade/">started increasing</a> their trade again, most notably <a href="https://unctad.org/system/files/official-document/ditcinf2021d1_en.pdf">in East Asia, spearheaded by China</a>.
The COVID-19 recession is very different from previous ones. A state-imposed demobilisation of the economic system occurred ranging from general shutdowns to milder non-pharmaceutical interventions (NPIs). Output fell, in the first instance at least, because the state intentionally switched off certain sectors, like most of retail, tourism and hospitality.
The size of the recession varied depending on how long and severe the NPIs were, as well as on the size of countervailing government interventions and trend growth prior to the pandemic.<br />
A few countries struggling with civil wars, government default and/or large-scale disasters experienced a collapse of economic activity (measured by GDP): Lybia (-67%), Lebanon (-25%) and Venezuela (-25%), followed by a few tourism-based mini-states.<br />
The contraction was <a href="https://www.imf.org/external/datamapper/NGDP_RPCH@WEO/OEMDC/ADVEC/WEOWORLD">more than 10% for some Latin American countries</a> (Peru, Argentina) and Spain that were hit hard by the pandemic and were fiscally constrained.
The fallout was around 10% for the worst hit European countries (UK, Italy, France) and India that applied  harsh but belated lockdowns without stemming mass infections and therefore were locked into cycles of relaxing and re-introducing NPIs.<br />
Japan, Germany, Brazil, the US, Australia/NZ and Eastern Europe saw recessions of around 5%. The reasons in this group of countries were diverse.
In the case of the US and to some extent Japan and Germany unconstrained fiscal intervention could be applied. In others trend growth had been higher (Brazil, Eastern Europe). Additionally, countries less reliant on services but having strong manufacturing exports (Germany, Japan, Eastern Europe) seem to have been less affected.<br />
Many African countries had mild recessions or even modest growth (-2 to +2%), but the Maghreb countries as well as South Africa and its neighbours experienced a &gt;5% contraction. China and Vietnam were two countries in 2020 that managed to suppress or prevent a mass outbreak [with the emergence of ‘Delta’, Vietnam has been struggling with mass infections and death since the summer of 2021] and sustained a +2% expansion which is still approximately 5% under their trend growth.
To summarise, the contraction of GDP was the most severe in Europe, Latin America and India, while in East Asia and sub-Saharan Africa the contraction was either smaller or there was even moderate growth.</p>

<p><img src="/images/covidcrash/2020_gdp_growth_imf.png" alt="_config.yml" />
[source: <a href="https://www.imf.org/external/datamapper/NGDP_RPCH@WEO/OEMDC/ADVEC/WEOWORLD">IMF datamapper</a>]</p>

<h3 id="response"><ins>Response</ins></h3>

<p>To make up for the fall in spending and the income loss of employees rich states took over much of the private sector wage bill, while almost all states implemented various measures increasing benefits, sending one-time down-payments to households or providing emergency loans and loan guarantees for businesses.<br />
The size of stimulus measures in 2020 was significantly bigger than in 2009. The exact numbers will depend on what is defined as part of the ‘stimulus’ on top of baseline spending, so absolute values are sensitive to methods.
Looking at numbers relative to 2009, according to the definition used by <a href="https://www.mckinsey.com/~/media/McKinsey/Industries/Public%20Sector/Our%20Insights/The%2010%20trillion%20dollar%20rescue%20How%20governments%20can%20deliver%20impact/The-10-trillion-dollar-rescue-How-governments-can-deliver-impact-vF.pdf">McKinsey</a> the size of the measures as a percentage of GDP increased 10-fold from 2009 to 2020 in Western European countries, Japan, Brazil and India, and around 3-5 fold for Canada and the USA.
According to the IMF’s breakdown of stimulus measures by type, <a href="https://www.imf.org/en/Topics/imf-and-covid19/Fiscal-Policies-Database-in-Response-to-COVID-19">much of them</a> were loans, loan guarantees and equity support and not direct spending. Nevertheless the spending increase itself was also about 12% of GDP in advanced economies (using the IMF’s definition). There is a big difference with emerging/middle income economies (EMMIE) where this figure was around 4% of GDP and low income countries where it was 1.5% on average.
Liquidity support was on average at the same level for advanced economies as additional spending, but in some countries such as Germany, Japan and Italy it was even higher, more then 30% of GDP, whereas in EMMIEs and low income countries liquidity support was smaller than the increase in spending.</p>

<p>It was at the cost of this unprecedented fiscal and monetary intervention that the state-ordered demobilisation of the economy did not lead to a collapse of national income.
By definition this means that government debt grew, reaching 100% of GDP globally, 10% above the projections made in 2019.
Fiscal intervention was one aspect of government interventions, but there was another one: monetary stimulus by central banks. Once again the money supply was significantly expanded, led by the Fed, but also the BoE, the ECB and the BoJ.<br />
One major difference from 2009 was that whereas then the largest stimulus was applied by China, which included both direct spending and (even more) expansion of credit to industry via its state-controlled banking sector, this time China implemented a (proportionally) smaller stimulus program than Europe and the US. This is mainly because lockdowns in China were much shorter and because of an early recovery no ‘furlough’-type programs of general wage support had to be applied.</p>

<h3 id="pandemic-prospects"><ins>Pandemic prospects</ins></h3>

<p>Vaccination programs are currently [Summer 2021] going ahead in Europe and North America and projected to cover most adults by the 4th quarter of 2021 in many Western European countries and some wealthy countries started to vaccinate adolescents as well.
The countries which managed to prevent or suppress outbreaks (in East Asia, Australia/NZ) were under less pressure to act quickly but also started their vaccination roll-outs while keeping their borders shut.<br />
Poor countries have much less access to vaccines so far, with Africa around a 2% vaccination rate by July 2021, Latin America around 40% and Asia around 30%.
Seroprevalence studies from urban areas of India, Pakistan and South Africa showed typically 20% to 50% of the adult population in cities already infected in early 2021, forming a level of population immunity, which is however not enough for the epidemic to end because of the more contagious variants (mainly ‘delta’) that appeared in 2021. Consequently, large outbreaks re-appeared from the spring of 2021, and are currently continuing through the summer. In late July 2021 some of these outbreaks, for instance in India and North Africa, are now [summer of 2021] again shrinking that could be a sign of population immunity.
Immune escape by new variants could undermine these calculations, but vaccines are likely to provide good protection at least against severe disease, and the timescale of adapting vaccines to new strains will likely become much shorter too.</p>

<p>A global coordination to eliminate COVID-19 by simultaneous lockdowns and travel bans seems unlikely both for political and technical reasons and given the contagiousness of Delta it is practically impossible to do.
The likeliest scenario then is vaccination providing protection for most of the population in high income countries, meanwhile in lower income countries higher population immunity due to infections, a multi-year vaccine roll-out and the much lower median age will keep the disease burden at a lower, but not negligible level.
Whether the disease burden has been in fact lower in low income countries so far is not clear as no reliable mortality statistics are available from many LICs, but <a href="https://github.com/dkobak/excess-mortality">excess death (per population) estimates</a> for South Africa are higher than for most of Europe and in Egypt comparable.
In Manaus, Brazil, the closest thing we have to an unmitigated epidemic on a large-scale, excess death estimates suggest 0.4% of the total population might have died and this was before the renewed outbreak from the summer of 2021.
<a href="https://github.com/dkobak/excess-mortality">Excess mortality analysis</a> suggests a similar level of mortality burden for the most heavily hit Latin American and East European/post-Soviet states with 3-6 COVID-19 deaths per 1000 population.<br />
With the appearance of the delta variant which is about 3 times more contagious than the original strain, countries that had previously successfully implemented a suppression and border closure policy, such as Taiwan, Vietnam, Thailand and China are in the summer of 2021 also seeing large outbreaks.
With the exception of China where more than half of the population are already vaccinated these countries have low (&lt;35% on the 1st of August) levels of vaccination. This means that they might experience levels of infections and therefore hospitalisations and deaths comparable to Europe/US in the Spring of 2020 and Winter of 2020-21. The low speed of vaccination in some East Asian countries raises questions about the narrative that their success in preventing mass outbreaks until the summer of 2021 was explicable by a more effective state and/or a more rule-abiding population. If slow vaccination rates are due to low demand, ie. vaccine hesitancy then the argument about state capacities could still stand, but it would still be inconsistent with culturalist explanations of law-abiding and/or collectivist attitudes.</p>

<p>In any case with the delta variant’s contagiousness on the one hand and vaccination programs on the other it is likely that most societies will reach a level of population immunity towards the end of 2021 so that sudden and large new outbreaks become less likely. Instead there would be a lower level of endemic transmission, modulated by seasonality, births and waning immunity. This could lead to SARS-CoV-2 adding a disease burden similar to one (or a few?) influenza season during the winter months.<br />
Assuming that vaccine programs and population immunity will keep the disease burden at a level below where governments would re-introduce strong NPIs, the economic recovery that started in most countries in the second half of 2020 or early 2021 is likely to continue through 2021.</p>

<h3 id="recovery"><ins>Recovery</ins></h3>

<p>Most larger economies have now positive growth rates and it seems there will be a strong recovery of GDP figures in 2021. In the United States the large fiscal and monetary stimulus is estimated to result in GDP not only recovering from the recession but even slightly exceeding the pre-pandemic GDP trend line. There is talk of inflationary pressures and shortages causing supply chain disruptions that are after-effects of the sudden shocks during the pandemic. Will these wear off or might they interact in a way to amplify each other and disrupt the recovery? Nobody knows for certain as economic models do not seem to be able to make reliable forecasts due to the complexity of the problem: both data and model structure are incomplete to make predictions with high confidence. The default forecast for the moment however is a recovery for this year and growth continuing in 2022.</p>

<p>Several things might derail this. First, there has been a massive buildup of corporate debt even before the pandemic since the 2009 recession.
<img src="https://thenextrecession.files.wordpress.com/2020/12/fin-3.png?w=500&amp;h=400" alt="_config.yml" />
During the pandemic a lot of businesses were kept on a government lifeline, in many cases meaning loans. Since ‘re-opening’ is unlikely to be a complete return to normality for industries like travel and hospitality, it is an open question if there will not be a chain of bankruptcies in 2021-22, which could start a new private debt crisis, perhaps this time starting from corporate debt, rather than housing and collateralised household (mortgage) debt as in the great financial crisis (GFC) starting from 2008.<br />
Another potential time-bomb could be the Eurozone, similarly to the 2010s following the first phase of the financial crisis: Greek government debt to GDP was ‘only’ around 110% in 2008 (then jumping to ~140% by 2010, and ~170% by the mid-2010s following austerity measures shrinking output further), but now it is 206%.
There has been a similar increase of public debt for Italy and Spain and indeed almost all EU countries. The difference is that this time, finally, the EU took a step towards the mutualisation of debt so that recovery programs should be to some extent funded jointly. This makes a run on Greek (etc) debt less likely, but does it make it impossible? The recovery program does not seem to be big enough (~300 billion euros in direct spending over a 7-year period, that is around 0.3% of the EU’s annual GDP) to generate much growth on its own and much of Southern Europe seemed stagnant already before the pandemic. Tourism is still to a large extent shut down and unlikely to completely recover this year. Where will growth come from in Southern Europe and if it does not, will these countries not face revenue problems that could cascade into a new sovereign debt crisis? If this will not happen and yields stay as low as they are and therefore interest payments manageable on Southern European government debt, this would support the view that the Eurozone debt crisis of the 2010s was avoidable and self-imposed by the inept and dogmatic policies of the EC/Eurogroup/ECB.
It is unclear if the European Commission (or whoever calls the shots on economic policies in the EU) have changed its views on what makes a recovery sustainable and would be willing to extend stimulus if growth rates slump or if it would switch back to austerity policies as in the early 2010s.</p>

<p>The UK might also experience a further shock if full custom controls with the EU are finally switched on: these were put off to October 2021 and some until January 2022. Disruption to trade with the EU have so far not been that significant (ie. seem to be recovering to the pre-2020 trend line), but this might change when full customs checks start to be applied. Nevertheless the effect so far looks more like a moderate drag on growth rather than a shock that could push the UK into recession. As long as there is ‘faith’ in the sterling and the government can borrow cheaply, the UK does not look like a domino likely to fall, thought its growth rate might no longer exceed that of the Eurozone as it <a href="https://ourworldindata.org/grapher/gdp-per-capita-worldbank?tab=chart&amp;stackMode=relative&amp;time=2000..latest&amp;country=Euro+area~GBR">mostly did</a> in the period 2000-2016.</p>

<p>An interesting question is why China was more cautious in its stimulus spending now compared to the GFC. Was it simply because it did not <em>need</em> to do more for its economy to rebound because of the rapid suppression of COVID-19 and its economy less dependent on exports? Or is there something more to this? If so, that ‘something’ could be (undisclosed) problems in the Chinese banking sector that makes the government not wanting to put more strain on it by forcing banks to up the credit supply.</p>

<p>Finally, there has been a <a href="https://www.iif.com/Portals/0/Files/content/IIF20200408_MN.pdf">large outflow of funds</a> from ‘emerging markets’, much more so than in the first 1-2 years of the GFC. While lower and middle income countries have run up government deficits much less than high income ones, their debt levels still increased, typically in the range of 5-10%, because of lost revenue and (modestly) increased spending. Medium-sized countries like Turkey, Brazil, Argentina, Mexico or Indonesia with a history of sovereign debt crises saw their debt levels rise and it is a question if the currency or the banking sector might snap in some of them if capital flows do not return to their pre-pandemic level and there is too much debt that cannot be rolled over or interest rates on debt spike.</p>

<h3 id="what-about-globalisation"><ins>What about globalisation?</ins></h3>

<p>Whether the recovery will be sustained for at least the coming 1-2 years or not, in retrospect I feel there were more fundamental problems with my <a href="https://mbkoltai.github.io/illusion-globalisation">arguments</a> on the fragility of globalisation.
The structure of the argument was the following. Globalisation on the current scale is rather recent: it mostly happened since the second world war and especially in the last 40-50 years - more a sudden explosion than gradual growth over centuries.
Although there had been some degree of globalisation ever since the sixteenth century and by some measures even before, for millennia, the cumulative growth of the last seventy years in terms of volumes of traded goods/services and of global economic output and energy use is (much) larger than what had occurred between the first civilisations and 1945.<br />
In the last forty years of explosive growth of international financial and trade flows there has also been a secular growth of all forms of debt, especially in the wealthy countries: corporate, household and public debt rose to levels several times of annual output. The two long business cycles (1992-2000, 2001-2007) before the GFC have been notoriously debt-driven, especially in the United States and Europe (Southern Europe, the UK, Ireland…), but also parts of Asia and Latin America.
The 1992-2000 cycle was marked by a debt-fueled stock market bubble (dotcom bubble) and the 2001-2007 cycle by unprecedented housing bubbles and debt-financed household consumption. Employment growth for the more recent business cycles was <a href="https://www.cbpp.org/job-growth-greater-than-in-2001-2007-ended-in-march-2020-4">weaker</a>, and the <a href="https://www.economist.com/img/b/1280/761/90/sites/default/files/20190706_WOC339_1.png">same</a> <a href="https://investors-corner.bnpparibas-am.com/economics/graph-of-the-week-the-new-mediocre/">goes</a> for output growth, with the long business cycle following the GFC (2009-2020) the weakest of all by both metrics.<br />
In short, what I argued was that 1) global trade networks expanded so fast that supply chains have become too stretched and many economies too dependent on trade, while 2) all sources of demand (consumer, business and government spending) are too reliant on debt. 3) When the system is hit by simultaneous shutdowns of much of the global economy it might not have enough resilience to withstand this and there could be an implosion in globalisation unlike anything since its emergence.</p>

<p>While there was a roughly 5-10% contraction in output and trade in 2020, it was comparable to that of 2009 and following government interventions there has been a strong rebound.
There are currently shortages in some goods (eg. computer chips) but overall supply chains of multinational companies could manage the shock of lockdowns: a 10% reduction in economic activity is not a collapse, and in fact it was mainly services, not manufacturing that was shut down. The idea that the shock was too ‘systemic’, so corporations will not be able to cope was therefore somewhat of a ‘handwavy’ argument. In reality they could manage it, at least with the help of governments. It is true that without government loans/grants/subsidies there might have been a real collapse, but government intervention to keep the economic system ticking was essential in the GFC (and before) already. Overall, the system was robust enough to withstand the storm.
The debt hangover from government interventions might still be a problem, either in the form of unviable businesses not being able to pay back loans or sovereign debt crises. If that happens, we could say the problem was just put off but not solved and the global economic system <em>was</em> too fragile and debt-ridden.<br />
The world economy can arguably be described as ‘unstable’ in the sense that there is a strong interdependence across markets and a mountain of debt in the system, so there can and will be periodic debt crises that spread rapidly. But this does not mean the system is close to a tipping point where it might collapse, if by collapse we mean a fall in activity of at least 30-50%. While some Marxist economist claim profitability is at a record low currently, nominal <a href="https://www.schroders.com/en/uk/private-investor/insights/markets/how-european-corporate-profits-powered-ahead-in-q1/">corporate</a> <a href="https://tradingeconomics.com/united-kingdom/corporate-profits">profit</a> <a href="https://tradingeconomics.com/united-states/corporate-profits">figures</a> seem to be recovering (Q1-Q2 2021). Even with more ‘<a href="https://thenextrecession.files.wordpress.com/2021/01/fore206.png">zombie companies</a>’ around, the recovery should go ahead at least in the short term.</p>

<p>But in a more general sense I think the line of argument was faulty: the fact that globalisation arose very rapidly and that a lot of debt has been built up since the 1980s does not imply it is an inherently fragile system and might collapse when hit by a large shock like the pandemic. First of all, complex systems often emerge in a burst, after a much longer period of slower growth. The institutional, legal and cultural basis for global trade had been there for a much longer time, and it was new information technology, regulatory frameworks for trade, finance and investment and cheaper shipping and travel that made the explosion after the second world war and again from the 1980s possible. But burst-like growth does not mean a system is out of control and headed for collapse: a sigmoidal curve has a first part that looks exponential but then it saturates.</p>

<p>That is for the macroeconomics in the short term. But what about climate change and the need for an energy transition? Could this be the ‘systemic’ crisis that tears down globalisation?
This question invites trying to make predictions about the climate, the world economy and politics at the same time - the complexity is so high it is doubtful even qualitative predictions are possible. I will still try to make some, while emphasising the following are just speculations, where I’ll only list the ‘branches’ that seem to me the most likely, although obviously there are many other possible futures.<br />
It is unlikely the response to the climate crisis will be fast enough since the crisis is already ongoing. Targets for decarbonisation have been recently set by the major economies, with China setting a target of emissions <em>peaking</em> by 2025-2030 and reductions only afterwards. The announced targets set out timelines of emission reductions that fall short by one or two decades to avert &gt;2C warming. Burning coal, probably the worst form of fossil fuel consumption, will still be going <em>up</em> for at least several years (around 5%/year currently), though for net zero emissions a yearly reduction of around 5% would be needed.<br />
So the most likely scenario would be the climate crisis getting worse: more extreme weather events, summer heat waves and forest fires. But these changes are likely to be woven into the fabric of a globalised capitalist economy instead of totally disrupting it: mitigating the climate crisis will create various new industries and new forms of population control.
The pandemic might be a dressing rehearsal in this sense as well: the precedent is now set for the state to drastically intervene and close down cities or even countries and ramp up surveillance. In the climate crisis, moving populations and forms of migration control will likely become part of the normal functioning of the state. The climate emergency, higher fuel costs and more home-working might result in somewhat less travel and perhaps more regionalisation of the world economy. Travel and migration for highly qualified professionals and of course for the rich are unlikely to be controlled or significantly reduced.</p>

<p>More broadly, cultural globalisation based on near-universal internet and smartphone use will likely continue, along with the spread of English. The secular decline in political participation (turnout at elections, party and union membership) will also likely go on, further hollowing out Western liberal democracies. Liberal-democratic states will likely become more and more technocratic and regulatory apparatus run by professionals from elite universities with the general population caring less about such things while an apolitical, individualistic and hedonistic consumer attitude focused on instantaneous gratification - hot-takes and takedowns - becomes ever more deeply entrenched.
This does not mean there will not be flare-ups of potentially violent forms of political protest, but these will likely be short-lived single-issue protest movements along the ‘Gilets Jaunes’ model: ideologically heterogeneous and confused, operating by memes and generally anti-political (‘they are all bastards’ etc) without creating organisational structures - and therefore likely to be short-lived. Right-wing populist governments might still be elected and cause some turbulence, but Europe’s far-right seem to be ‘normalising’, accepting euro-realism (EU and Eurozone membership with its budgetary rules and elite secrecy), so such governments might be distinguishable mainly by their immigration policies being somewhat more cruel. Social inequality and related discontent will likely be addressed by progressive technocrats of the Elizabeth Warren type in the very best case.<br />
In countries where political pluralism has only weak roots in society there will likely be a move towards ‘managed democracies’ along the lines of Russia or Hungary, with a hegemonic government party using broadcast and social media as well as high-tech surveillance to keep opposition groups marginal enough so that open repression is only occasionally needed.
While some of these ruling elites might fall, it is unlikely this will lead to a general upsurge of political participation, instead they will be replaced by another oligarchic group that takes hold of the state and the adjoined rent-seeking apparatus as a revenue stream.
Consent will be bought by the state via providing some level of stability and support for the least well-off outside the metropolitan centres along with culture wars against the ‘woke’ West and metropolitan liberals, while those within the city gates are allowed to either pursue a lifestyle of Westernised consumption or emigrate.</p>

<p>In the global South climate change might be truly catastrophic because of the effects of rising temperatures on both human health and agriculture. This will increase migratory pressure on the West and in the intermediate zones especially around Europe (North Africa, the Sahel and the Middle East). Repressive states in this buffer zone will likely get more funding from the West in exchange for holding back migrants by force.</p>

<p>Overall, I would expect global trade and information technologies to survive under conditions of the climate crisis too. Travel and migration for elites and professionals will probably be secured, but might be more curtailed for others. In this respect the travel bans and other restrictions of the pandemic could prove to be templates.</p>]]></content><author><name></name></author><category term="political-economy" /><category term="globalization" /><category term="climate-change" /><category term="complex-systems" /><category term="ecology" /><category term="epidemics" /><category term="covid19" /><category term="growth" /><summary type="html"><![CDATA[Follow-up to 2020 article on globalisation]]></summary></entry><entry><title type="html">Analytical solutions of SIR models</title><link href="http://localhost:4000/covid-modeling/" rel="alternate" type="text/html" title="Analytical solutions of SIR models" /><published>2020-04-18T00:00:00+01:00</published><updated>2020-04-18T00:00:00+01:00</updated><id>http://localhost:4000/covid-modeling</id><content type="html" xml:base="http://localhost:4000/covid-modeling/"><![CDATA[<p>These notes were written in the early stage of the COVID19 pandemic and they explore general properties of compartmental transmission (SIR-type) models.<br />
The models below make no specific predictions, instead I am only looking at their general mathematical properties.</p>

<h3 id="sir-models"><ins>SIR models</ins></h3>

<p>Let’s start with the simplest epidemic model, ie. the SIR compartmental model, where we have:<br />
\(\frac{dS(t)}{dt}{=}{-}\alpha S(t) I(t) \\
\frac{dI(t)}{dt}{=}\alpha S(t) I(t)-\beta I(t) \\
\frac{dR(t)}{dt}{=}\beta I(t)
\tag{1}\label{SIR_odes}\)</p>

<p>It is more convenient to work with fractions of a population (and not absolute numbers), so that we have the conservation \(S(t){+}I(t){+}R(t){=}1\).
We need to keep in mind that this is a mean field ODE model and <strong>has many limitations</strong>. It assumes complete homogeneity of transmission events, ie. that they depend only on the <em>fraction</em> of the population susceptible and infected and that for given values of these fractions we have the same rate of transmissions.
This also means that any small nonzero values for the infected population will lead to transmissions, whereas in reality a very small fraction can mean so few infected individuals that the epidemic can just die out. Also, in reality transmission events (very probably) do <em>not</em> occur homogeneously, proportionally to the infected (and susceptible) fraction of the entire population, but are much more clustered, local and occurring in certain environments, in burst-like (‘superspreader’) events.
For these reasons it is important to stress that these SIR models should be interpreted very cautiously and we must keep in mind their assumptions that are not entirely correct.
Nevertheless, they can give us a first idea of some general properties of epidemic dynamics and that’s what I want to do here. For predictions and planning more advanced models that take into account local environments, stochasticity, rare spreading events etc should be used, and it can also be useful to use <a href="https://static1.squarespace.com/static/5b68a4e4a2772c2a206180a1/t/5e8e5ac9e696ba4b972093fa/1586387658680/Modeling2.pdf">very simple but probabilistic models</a>.</p>

<p>In the SIR framework it is clear that \(I(\infty){=}0\), since this variable has first-order (linear) decay, so any nonzero value in this compartment eventually ‘leaks out’ into \(R\).
Therefore the equilibrium of the system is \((\overline{S},0,\overline{R})\) and due to the conservation \(\overline{R}{=}1{-}\overline{S}\). So to characterize the stationary behavior of the system all we need to calculate is
\(\overline{S}\).</p>

<p>Of course this can be done by numerically integrating the ODEs in \ref{SIR_odes} and indeed half the internet is full of SIR-models now. But how about an <a href="http://http://mbkoltai.github.io/exastolog/">exact solution</a>?<br />
In this very clear <a href="https://www.nature.com/articles/s41591-020-0883-7">paper in Nature Medicine</a> (and probably others before) the authors explicitly derive the stationary solution for a more complicated model of 8 variables they abbreviate as the ‘SIDARTHE’ model.
Despite the apparent complexity this model is basically identical to the simple SIR model. The only difference is that 1) the \(I\) variable is split into several sub-variables (<strong>I</strong>: infected, a-/presymptomatic, undetected, <strong>D</strong>: diagnosed (asymptomatic infected, detected); <strong>A</strong>: ailing (symptomatic infected, undetected); <strong>R</strong>: recognized (symptomatic infected, detected); <strong>T</strong>: threatened (infected with life-threatening symptoms, detected)) 2) the sink variable <strong>R</strong> of the SIR model is split into two sinks (<strong>H</strong>: healed (recovered); <strong>E</strong>: extinct (dead)). However the \(IDART\) ‘module’ (the five state variables representing different stages of infection) has the same basic property as <strong>I</strong>, namely that in \(t{\rightarrow}\infty\) they decay to 0, and only <strong>S</strong>, <strong>H</strong>, <strong>E</strong> can have nonzero values.</p>

<p>For the simple SIR model defined of \ref{SIR_odes} the solution for the stationary value of \(\overline{S}\) is less complicated than in the latter model, ie. it is given by the implicit expression:<br />
\(\frac{\alpha}{\beta} \overline{S} - log\overline{S} = \frac{\alpha}{\beta} - logS(0)
\tag{2}\label{SIR_S_stationary}\)</p>

<p>This can be solved by an efficient algebraic solver such as \(fsolve\) in MATLAB.
Let us do a parameter sweep in the \(\frac{\alpha}{\beta}\) ratio and the initial value of \(S(0)\), and look at the stationary solution of <strong>R</strong>, ie. the fraction of the population that went through infection (ie. is now immune, if there is long-term immunity). Let us also check if the algebraic formula is the same as integrating the ODEs of \ref{SIR_odes} for a long time span:
<img src="/images/covid/SIR_immune_pop_algebr_ode_sol.png" alt="_config.yml" />
<em>Figure 1: Stationary solutions of SIR model calculated by simulations (left) and exact calculations (right)</em></p>

<p>Fortunately the analytical solutions from \ref{SIR_S_stationary} are identical with the numerical solutions of the ODEs, so we didn’t make a mistake in \ref{SIR_S_stationary}.<br />
What do we see from this plot? The \(\frac{\alpha}{\beta}\) ratio is the famous \(R_0\), the basic reproduction parameter, and logically, the larger this ratio is, the more of the population will go through infection (again, in the framework of this extremely simplified model not meant to be realistic).
It is also intuitive that if \(S(t{=}0)\) is smaller because of a larger initial infected population \(I(0)\), then \(\overline{H}{+}\overline{E}\) will be larger.</p>

<p>Now, let us make the model one step more refined, and split <strong>R</strong> into two variables, <strong>H</strong>(ealed) and <strong>E</strong>(xtinct , ie. deceased), as:</p>

<p><img src="/images/covid/SIHE_cropped_resiz.png" alt="_config.yml" />
<em>Figure 2: ‘SIHE’ version of the SIR model where <strong>R</strong>(recovered) is split into <strong>H</strong> and <strong>E</strong></em></p>

<p>The <strong>I</strong>(nfected) variable now has two outcomes. It is clear intuitively that this will not change how the stationary solution of \(\overline{S}\) is calculated, as the sink nodes do not interact with <strong>S</strong>, except that now <strong>I</strong> has two outgoing flows, so it is the ratio \(\frac{\alpha}{\lambda{+}\tau}\) that will define \(\overline{S}\) as:
\(\frac{\alpha}{\lambda{+}\tau} \overline{S} - log\overline{S} = \frac{\alpha}{\lambda{+}\tau} - logS(0)
\tag{3}\label{SIHE_statsol_S}\)</p>

<p>Moreover we can give the formulas for \(\overline{H}, \overline{E}\) as a function of \(\overline{S}\) and the initial infected population \(I(0)\).
It is reasonable to assume \(H(0), E(0)\) are 0.
Downstream of <strong>I</strong> the dynamics is completely linear: what flows out from <strong>S</strong> into <strong>I</strong> (ie. \(\Delta{S}{=}S(0){-}\overline{S}\)), as well as the initial concentration of \(I(0)\) will be partitioned into the sink variables proportionally to the rate constants \(\lambda\) and \(\tau\). Specifically, we’ll have:<br />
\(\overline{H} = [(S(0)-\overline{S}) + I(0)] \frac{\lambda}{\lambda{+}\tau}\\
\overline{E} = [(S(0)-\overline{S}) + I(0)] \frac{\tau}{\lambda{+}\tau}  
\tag{4}\label{SIHE_statsol_H_E}\)</p>

<p>The ratio \(\frac{\tau}{\lambda{+}\tau}\) is the infection fatality (IFR) rate.
It is clear from \ref{SIHE_statsol_S} that the IFR does not affect \(\overline{S}\) if the sum \(\lambda{+}\tau\) is kept constant, it is instead the ratio of \(\alpha\) (rate constant of new infections) to these two parameters that determine at what level of total infections the epidemic stops.
To check if the formulas are correct, let us again compare the exact solution to the numerical solution of the ODEs, and plot the stationary solutions of \(\overline{S},\) at different IFR values:
<img src="/images/covid/SIHE_algebr_ode_IFRscan.png" alt="_config.yml" />
<em>Figure 3: stationary solutions of SIHE model at S(0)=0.99 and four different values of the IFR</em></p>

<p>Circles show the results from numerical integration of the ODEs, confirming they are identical with the analytical solutions (lines). The fraction of the population that has not been infected throughout the epidemic (\(\overline{S}\)) goes down with \(\frac{\alpha}{\lambda{+}\tau}\), but is independent of the IFR as the sum \({\lambda{+}\tau}\) was kept constant here. The ratio \(\frac{\alpha}{\lambda{+}\tau}\) expresses how fast subjects exit the infectious state relative to the rate constant of generating new infections. A higher ratio means more of the population is infected, which is \(\overline{H}+\overline{E}=(S(0){-}\overline{S}){+}I(0)\).
In contrast, if both \(\alpha\) and \(\lambda{+}\tau\) are equally scaled then this quantity does not change.<br />
How the infected fraction of the population is partitioned between the two sink states (\(\overline{H}, \overline{E}\)) obviously depends on the IFR (note the logarithmic scale), as stated in \ref{SIHE_statsol_S}.
Note that while the IFR is ‘hard-wired’ in the parameter ratio \(\frac{\tau}{\tau+\lambda}\), how much of the population gets infected and dies depends on \(\overline{S}\) and therefore \(\alpha\), the rate constant for transmission. This is where physical distancing measures would intervene to choke off the flow \({S}\rightarrow{I}\).</p>

<p>Let us go now one step further and allow for a pre-symptomatic state, defining <strong>I</strong> as a variable of the infectious but pre-symptomatic state and adding a variable <strong>A</strong>(iling) that is the infectious and symptomatic state. Now the compartments of this ‘<em>SIAHE</em>’ model and the flows between them are:</p>

<p><img src="/images/covid/SIAHE_res.jpeg" alt="_config.yml" />
<em>Figure 4: ‘SIAHE’ SIR model with presymptomatic (<strong>I</strong>) and symptomatic (<strong>A</strong>) infectious state and two outcomes</em></p>

<p>By highlighting the \({S}\rightarrow{I}\) flow in red I want to indicate that this is the (only) nonlinear term, and now this flow has two parameters as the ODE for <strong>S</strong> is:<br />
\(\frac{dS(t)}{dt} = -S(t)(\alpha I(t) + \gamma A(t))\)</p>

<p>These two bilinear terms are positive feedbacks on the otherwise linear system. If it wasn’t for these terms the system would have an equilibrium where only the <a href="http://vcp.med.harvard.edu/papers/jg-lap-dyn.pdf">terminal vertices</a> (\(H, E\)) of its graph can have nonzero value, just like with the equilibrium we have for the <a href="https://mbkoltai.github.io/exastolog">state transition graph of a stochastic Boolean model</a>.
Because of this nonlinear feedback however <strong>S</strong> can (and usually does) also have a nonzero value in steady state, so the equilibrium of SIAHE is \((\overline{S},0,0,\overline{H},\overline{E})\).</p>

<p>Let us again get the formula for \(\overline{S}\). Ff we have this, the rest of the system has linear kinetics, so the stationary values of <strong>H</strong> and <strong>E</strong> will follow easily from the kinetic matrix of the IAHE variables. I follow here the derivation from the Nature Medicine article, except that it is for a simpler (5 variables) model.</p>

<p>We need to introduce some notation:<br />
\(x(t){=}\begin{bmatrix} I(t) \\ A(t) \end{bmatrix},
c{=}\begin{bmatrix} \alpha \\ \gamma \\ \end{bmatrix},
b{=}\begin{bmatrix} 1 \\ 0 \end{bmatrix},
F{=}\begin{bmatrix} -(\lambda{+}\zeta)&amp;{0}\\{\zeta}&amp; -(\kappa{+}\tau) \end{bmatrix}\)</p>

<p>Then the ODE for \(I(t)\) and \(A(t)\) is:<br />
\(\dot{x(t)}{=}F x(t) + b c^T x(t) S(t)\)</p>

<p>Since \(\dot{S}(t){=}-c^T x(t) S(t)\) we can substitute this in and get:  <br />
\(\dot{x(t)}{=}F x(t) - b  \dot{S}(t)\)</p>

<p>Then integrating (and changing \(t\) to \(\phi\)), for the left side:<br />
\(\int_0^\infty \dot{x}(\phi) d\phi = x(\infty){-}x(0){=}-x(0)\)</p>

<p>…and on the right hand side we have:<br />
\(F\int_0^\infty x(\phi) d\phi - b \int_0^\infty \dot{S}(\phi) =
F\int_0^\infty x(\phi) d\phi - b(\overline{S}-S(0))\)</p>

<p>so then we have:<br />
\(-x(0){=}F\int_0^\infty x(\phi) d\phi - b(\overline{S}-S(0))\)</p>

<p>Now if we pre-multiply by \(c^T F^{-1}\) (a [1x2] vector) to get rid of F and to turn both sides into scalars we get:<br />
\(-c^T F^{-1} x(0) =\int_0^\infty c^T x(\phi) d\phi - c^T F^{-1} b(\overline{S}-S(0))\)</p>

<p>From the ODE of \(\dot{S}\) we can substitute \(\frac{\dot{S(t)}}{S(t)}\) into \(c^T x(t)\):<br />
\(-c^T F^{-1} x(0){=} - \int_0^\infty \frac{\dot{S}(\phi)}{S(\phi)} d\phi - c^T F^{-1} b(\overline{S}-S(0)) = log \frac{S(0)}{\overline{S}} - c^T F^{-1} b(\overline{S}-S(0))\)</p>

<p>Then after a rearrangement we have the solution for \(\overline{S}\) in the same form as for the ‘<em>SIHE</em>’ model in \ref{SIHE_statsol_S}:<br />
\(-c^T F^{-1}b \overline{S} - log \overline{S} = -c^T F^{-1}b S(0) - log S(0) + c^T F^{-1} x(0)\)</p>

<p>\(-c^T F^{-1} b\) is the \(R_0\) of this version of the model, so rewriting with \(R_0\):<br />
\(R_0 \overline{S}- log \overline{S} = R_0 S(0) - log S(0) + c^T F^{-1} x(0)
\tag{5}
\label{SIAHE_S_statsol_R0}\)</p>

<p>Explicitly, \(R_0\) is:<br />
\(R_0{=}\frac{\alpha}{\lambda+\zeta}{+}\frac{\zeta \gamma}{(\kappa+\tau)(\lambda+\zeta)}\)</p>

<p>\(R_0\) is linearly increasing in the contagion rates \(\alpha\) and \(\gamma\), while decreasing in the rate constants of the outgoing flows of <strong>I</strong> and <strong>A</strong>, ie. \(\kappa, \tau, \lambda\).
\(\zeta\) has a more complicated effect as it decreases the first term, but increases the second. This makes sense too, since this is the rate constant <em>between</em> the two contagious states <strong>I</strong> and <strong>A</strong>.</p>]]></content><author><name></name></author><category term="epidemics" /><category term="complex-systems" /><category term="covid19" /><summary type="html"><![CDATA[Stationary behavior of compartmental epidemic models]]></summary></entry><entry><title type="html">1990-2020, the false dawn of globalization?</title><link href="http://localhost:4000/illusion-globalisation/" rel="alternate" type="text/html" title="1990-2020, the false dawn of globalization?" /><published>2020-02-29T00:00:00+00:00</published><updated>2020-02-29T00:00:00+00:00</updated><id>http://localhost:4000/illusion-globalisation</id><content type="html" xml:base="http://localhost:4000/illusion-globalisation/"><![CDATA[<p>As the coronavirus is spreading through the world I have been overcome by a feeling similar to an optical shift. If you have looked at a <a href="https://en.wikipedia.org/wiki/Random_dot_stereogram">stereogram</a>, you know what I mean: out of random dots a three dimensional pattern emerges.</p>

<p>Almost irrespectively of political taste, most of us, at least in middle and high-income countries, have experienced these last decades of expanding world trade, cheapening travel, instantaneous communication and product availability as a never-ending ahistorical present, a normality taken for granted. In reality maybe it was a very fragile and unsustainable experiment, about to be swept away.</p>

<p>I have lived my whole life in the era after the fall of the Soviet Union, a monotone steady-state of globalized consumer capitalism, unchallenged as a system. Obviously, in many world regions the period has been anything but steady - it meant almost permanent war in the Middle East, and periods of violence in the Balkans, Ukraine, parts of Africa etc. The 2008 crash, the following gradual implosion of the political center and rise of right-wing populism to electoral victories (2010: Hungary, 2014: India, 2015: Poland, 2016: US &amp; Brexit, 2018: Brazil) signaled a general shift in the management of global capitalism.
Still, the characterizations of ‘globalized’ and unchallenged as a system still stand.
If the era is to be summed up in one word it is probably ‘globalization’.
Now it feels like an infinity since we have been ‘globalized’, doesn’t it?
It is easy to miss just how condensed this process has been in time. To see that, it is helpful to zoom out a little bit.</p>

<p>The explosion in <a href="https://en.wikipedia.org/wiki/World_population_estimates">world population</a> predates globalization and was a slower process.
But it has also almost completely happened in the last century and especially its second half. Most estimates put the global population between 200-300 million at the time of AD 1.<br />
It stayed nearly flat until 1500, when it reached half a billion.<br />
It took <em>three centuries</em> for the global population to double again to reach one billion around 1820.
Then it doubles again in a century, reaching 2 billion by 1930.<br />
But then the dynamics changes: 3 billion by 1960 (30 years to grow by a billion), 4 billion by 1974 (14 years), 5 billion by 1987 (12 years), 6 billion by 1999 (12 years), 7 billion in 2011 (12 years).<br />
The increase over the last two thousand years is from 0.3 to 7.5 billion. That growth is extremely condensed in time: 90% of it happened in the last 10% (two hundred years) of this period, and almost 80% in just the last century. A bit more than half of the entire increase (from 3.7 to 7.5 billion) happened in the last 50 years. That is just the last 2% of the AD era.</p>

<p>Economic growth is even more concentrated. Most human activity in pre-capitalist, pre-industrial societies did not take the form of commodity production, of goods produced to be sold in exchange for money.
Therefore projecting back monetary estimates of world GDP before the 19th century is not to be taken literally, ie. these estimates do not correspond to money incomes or ‘value added’ (and realized in sale), as most human effort did not lead to any sale or payment of a wage.
Still, the <a href="https://www.oecd-ilibrary.org/development/the-world-economy_9789264022621-en">rough estimates by Angus Maddison</a>, <a href="https://delong.typepad.com/print/20061012_LRWGDP.pdf">Brad De Long</a> and others give some ballpark figures for the total amount of human work performed on the planet. From the 19th century on they can be viewed increasingly as estimates of ‘economic’ activity, ie. all activity followed by monetary exchange.<br />
Until technology comes into the picture, physical output should move together with the population size.
That is roughly what happens: according to <a href="https://delong.typepad.com/print/20061012_LRWGDP.pdf">DeLong’s estimates</a> ‘gross world product’ grows threefold in the fifteen hundred years from 1 AD to 1500, from around 20 billion <a href="https://en.wikipedia.org/wiki/International_dollar">1990 US dollars</a> (Int$) to 60 billion. (Again, this is a counterfactual: if the things made back then had been all for sale and could be bought with US dollars from 1990 by fixing their purchasing power.)<br />
Similarly to population, it takes another three centuries to triple to 175 billion in 1800.<br />
From that time point the effect of industrial technology becomes visible in the numbers.
Output doubles in 50 years by 1850 (360 billion), then triples to 1.1 trillion in another half a century by 1900. Another doubling comes in a <em>quarter</em> of a century by 1925 (2 trillion) and yet another by 1950 (4 trillion) despite the destruction of the Great Depression and the Second World War.
With the post-war boom the doubling time becomes little more than a decade: it passes 8 trillion (8e12) in the early sixties, 15 trillion by the mid-70s, 30 trillion in the early nineties. The current world GDP of 80 trillion USD is approximately 60 trillion Int$ (1990 US dollars).<br />
Altogether, in two thousand years there is an increase in yearly ‘gross world product’ from something like 0.02 trillion to 60 trillion.
Of this approximately 60 trillion total increase 59 trillion, that is <em>more than 98% has occurred in just the last one hundred years</em>, the last 5% period of these two millennia. Recall, for population ‘just’ 80% of the total increase is concentrated in the same period.
But even within that period there is a further condensation into the post-war period, as more than <em>90% of all economic growth happened since 1950 and around half of it in the last 30 years</em>.<br />
In short, when it comes to economic growth in aggregate numbers, almost all of it has been since the end of the Second World War. <sup id="fn1"><a href="#myfootnote1">(a)</a></sup><br />
Clearly the population increase was enabled and caused by industrialization and urbanization and with an expanding work force fed back into the growth of physical output, itself immensely amplified by cheap energy (fossil fuels) and technology.
Global population increased ‘only’ around 5-fold since 1900 (from 1.6 to the current 7.5 billion), in contrast to a 50-60-fold increase in economic output.
An order of magnitude difference accounted for by the 10-fold increase in per capita output. This is looking at the averages: in fact that growth was also geographically concentrated (although gradually less so from the 1970s with the growth of East Asian economies) so per capita output growth has been even steeper in some countries.<br />
Economic growth is a second-order process on the back of population growth. The two mutually amplify each other and the former internally amplifies itself via technological development.
Economic growth is much faster, as the total output is population times per capita output, both on an upward trend that can be fit by exponentials. An average yearly growth rate of 1.4% roughly generates the 5-fold increase (\(1.014^{120}{\approx}5\)) in 120 years (population), and 1.9% yields a 10-fold increase (per capita output).
The two of them combined into the 3-3.5% average growth rate of total output over the last 120 years when almost all (98%) economic growth has occurred in the history of humanity.</p>

<p>Globalization is then third-order: it is the network of connections between the hotspots of industrial production, the flow of goods, money, people and information.
It’s a process that starts at a higher level of differentiation and requires even more complex legal, infrastructural and communicational structures than production and exchange at a given location, or within a region or nation state.
<em>A priori</em> then it would be logical that it is even more compressed in time.<br />
In the 1990s with the growing globalization literature there were anecdotic or more serious attempts to dismiss the scale of the phenomenon by referring to the ‘first globalization’ from the late nineteenth century until the Great Depression.
Looking at <a href="http://www.cepii.fr/cepii/en/bdd_modele/presentation.asp?id=32">exports as a percentage of global GDP</a> this seems true at first sight, comparing the period 1870-1930 to 1930-1970: the exports/GDP ratio exceeded 10% in 1871, hovering slightly above that level until 1930, from where it crashed back to 5% by 1935, first exceeding 10% again in 1973.
But these are percentage figures and meanwhile the world economy grew enormously.
So 10% of world GDP in 1871 and 1973 mean completely different things: the figure in 1973 <em>refers to a 35-times larger volume of exported goods</em>, almost two orders of magnitude more. <sup id="fn2"><a href="#myfootnote2">(b)</a></sup><br />
These two moments of economic history are on very different levels of globalization.<br />
But the bulk of the globalization process only starts from the early 1980s. There is a first burst of the exports-to-GDP ratio from 10% to 15-17% from 1973 to the mid-1980s. But then it shoots up to 30% of global GDP by 2008, dented by the financial crisis, again standing at 30% last year.
In absolute terms, <a href="https://data.worldbank.org/topic/trade">global merchandise exports</a> have grown about 60-fold since 1970, 10-fold since 1980 and 5-fold since 1990. As expected, this is even faster than the growth of global GDP (25-, 8- and 4-fold since the same dates, respectively).
Looking at sub-processes such as <a href="https://data.worldbank.org/indicator/ST.INT.XPND.CD">international tourism</a> (expenditures, 1995-2018: 4-fold increase), total volume of <a href="https://unctad.org/en/Pages/DIAE/World%20Investment%20Report/Annex-Tables.aspx">foreign direct investment</a> (1990-2018: 6-fold increase), <a href="https://unctad.org/Sections/dite_dir/docs/WIR2019/WIR19_tab04.xlsx">the stock of foreign direct investment (FDI)</a> (1990-2018: 14-fold increase), cross-border acquisitions (<a href="https://unctad.org/Sections/dite_dir/docs/WIR2019/WIR19_tab10.xlsx">cross border M&amp;A purchases</a>, 1990-2018: 9-fold increase) the growth is even more massive.</p>

<p>The plot below highlights this concentration of the three exponential waves of population growth, economic growth and globalization into the last two centuries. To see the lags between economic growth and globalization we need to zoom in on these last two centuries, shown by the two insets.</p>

<p><img src="/images/illusionglob/world_pop_gdp_exports_log_yaxis_2insets_textboxes.png" alt="_config.yml" /></p>

<p>In short, the last 30-40 years saw the volume of most kinds of international transactions multiply several fold.
But I feel these numbers still understate the actual impact on everyday life. Lifestyle has changed fundamentally too.<br />
Low cost airlines have proliferated and reduced the cost of air travel dramatically, increasing total passenger number <a href="https://data.worldbank.org/indicator/IS.AIR.PSGR">4-fold since 1990, to 4 billion</a>.
At least in the core countries, flying no longer has much of a class distinction, something reserved for managerial elites. Almost everyone travels and flying to a sea resort in the summer is a must-do for many wage-workers.<br />
With Amazon and others virtually any commodity has become instantaneously available.
Impatient consumers live-track deliveries of goods shipped in from the other side of the world, expected within days or even hours, thanks to burgeoning warehouse and delivery systems that seem to have replaced much of manufacturing employment in the West.<br />
Exchanges in higher education have grown enormously, there are close to <a href="https://www.statista.com/statistics/372900/number-of-chinese-students-that-study-in-the-us">0.4 million Chinese students</a> now studying at US universities.
PhD programs have proliferated, in the sciences mostly populated by foreigners from poorer countries, creating a new technocratic class of precarious, uprooted research workers (I’m one of them) jumping between temporary (postdoc) positions and countries, often barely speaking the local language and with tenuous links to the host society, but as a mass of people becoming integral to the research infrastructure of high-income countries.<br />
Tens of millions of people moved to another country for work in the EU. Chinese migrant workers might be an order of magnitude more numerous, drawn to the coastal cities from the 1980s on by manufacturing jobs producing for Western and now global consumer markets.<br />
Finally, the number of internet users has grown from 0.4 in 2000 to 4.5 billion this year which means almost the entire global adult population of <a href="https://data.worldbank.org/indicator/SP.POP.1564.TO">5 billion people</a> has some access to it. Financial transactions, trade of physical goods, international travel, science, mass entertainment and increasingly interpersonal relationships are all built on it.</p>

<p>Cheap travel, mass international (or long-distance regional) mobility of workers, fast and universal availability of goods produced by global value chains, instantaneous and continuous exchange of data and communication: these have become the basic matrix of life, even if in very different forms, depending which end of globalization one is at - a web designer of a multinational fashion company in Germany and its seamstresses in Honduras or China live in different realities. Still, they were drawn into the same process, and all this happened very recently.<br />
Commodity production, wage labor and monetary exchange have only become the dominant forms of social reproduction in the last 100-150 years in the wealthy countries, and in much of the world only in the last 30-50 years.
Global inter-connectedness of a system of commodity production (globalization) really only emerged from the 1970s and especially from the late 1980s on.
This is a tiny period within not only human history, but even ‘modern history’ since the onset of European colonialism.</p>

<p>If you are under 40 this is the only history (or lack thereof) you know first-hand. Attempts at reviving radical left or social-democratic politics have (eventually and/or so far) failed and no systemic challenges have appeared on the horizon. Bloody regional wars have been launched or ignited, mainly by the leading military power (the United States). Much smaller scale, but more widely covered, terrorism has appeared in the core countries, but its ideologies (Islamist and white supremacist) did not offer a systemic alternative or a revolutionary politics. On the contrary, the terror acts were perpetrated in the name of revenge and a desperate conservative rejection of the present without any serious vision of an alternative future.
Overall, these disruptions did not question the tacit or explicit assumption that globalization simply cannot stop. It has become our unquestioned normality.</p>

<p>The coronavirus epidemic/pandemic, the stark facts of climate change becoming undeniable (and <a href="https://www.lrb.co.uk/the-paper/v41/n15/francis-gooding/all-the-news-is-bad">far worse than previously thought to be</a>) and the near-total (and incidentally well-deserved) implosion of the political center in almost all major countries makes me wonder.
Was this all an illusion and, on a world historical scale, an ephemeral one?
Globalization has stretched global value chains and networks of travel, communication and exchange enormously in a very short period, pushing many of these networks probably operating close to their breaking point.
The global corporations running them have surely implemented feedback mechanisms to cope with perturbations, to ensure profits keep flowing.
But there is a growing impression that the safety mechanisms that exist might be <a href="https://necsi.edu/an-introduction-to-complex-systems-science-and-its-applications">mismatched</a> with respect to traumatic events such as a pandemic by <em>orders of magnitude</em>.
They can presumably deal with small perturbations: there is excess demand or a failure here, a fire in a warehouse or a failed bridge there. These are small clogs in huge systems of circulation, blocking one channel, quickly dealt with or compensated by others.
They happen on the micro-scale of the system, at the level of its small components, and the size of such events should be normally distributed.
Events like epidemics are systemic: they are on the scale of the entire system. They are very unlikely but if they do happen, since the system’s components are interdependent, they can spread through it with enormous speed.
Almost all electronics and clothing is produced in Asia: if a whole province in China is under lockdown, this can cripple the tech giants whose gadgets everyone uses. Europe has a shortage of masks and not much textile industry left (this in itself can be presumably solved, but look at the pattern). In any Italian hotel there are probably a few cancellations every month - but now more than 90% of visitors cancel.
The expansion of air travel made it very hard or impossible to stop the spread of a virus, but globalization can hardly work without it. The interventions probably required to radically reduce the connectivity of the system in order to stop propagation might lead to a global slump: once the chain of defaults and bankruptcies spread, there is no fast way back to the growth path before the event.</p>

<p>The speculative but not unreasonable question arises: have the last 30 years of globalization built up an unstable system hyper-connected by fragile networks, that inevitably generates critical events that it cannot deal with?
First, in a macroeconomic sense: the two long business cycles when globalization exploded, 1992-2000 and 2001-2008 were driven to an unprecedented degree by the expansion of private debt (<a href="https://tradingeconomics.com/united-states/households-debt-to-gdp">household</a>, <a href="https://fred.stlouisfed.org/series/NCBDBIA027N">corporate</a> and especially within the <a href="https://www.federalreserve.gov/releases/z1/20191212/html/d3.htm">financial</a> sector) and asset inflation (stocks in the 1990s; real estate and securitized assets from mortgages/consumer debt in 2000s), at least in Western Europe and the United States. The fuel of the process that made it possible was also its own poison: <a href="https://www.federalreserve.gov/releases/z1/20191212/html/d1.htm">5-15% yearly growth in debt</a> could not be serviced by economies growing at 3% and most households with stagnant incomes.
At some point the chain had to break and securitization had ensured the toxic debt was scattered through the entire global financial system causing a systemic shock. The recapitalization of the banking system by the major states that followed, without significant financial reform, but austerity policies for the general population, destroyed the credibility of the technocratic/free-market political center that had managed the ‘golden years of globalization’ 1990-2008. The breakdown of political legitimacy to the point of ungovernability (Italy, Spain) and the ensuing nativist/far-right revolt that once in power started to question, withdraw from or even dismantle the multilateral systems (trade agreements, UN organizations, the EU) of globalization is another systemic shock.<br />
Even more significantly, the exponential expansion of fossil fuel-based production across the globe has had the same temporal profile in terms of its energy use as in its growth counted in dollars.
<a href="https://cdiac.ess-dive.lbl.gov/trends/emis/tre_glob.html">Around half of all \(CO_2\) emissions</a> by humanity (around 800 out of 1600 Gigatons) has occurred in the exact same period, the last 30 years, and 85% since WWII.
Incredibly, during 30 years of globalization as much of the Earth’s energy reservoir (condensed into the deposits of fossil fuel) has been burnt up as in all human history before, unleashing a warming process that now, all evidence suggests, is very difficult to stop from reaching 3-4 centigrades.</p>

<p>These are not small-scale events that the safety mechanisms of global value chains, transportation networks etc. are designed to deal with. They can instead remove their basis as the effects rapidly spread through the same networks. I do not know whether the current coronavirus epidemic can still be stopped or mitigated so that it does not reach a critical level.<br />
But however this particular event turns out, it raises deeply alarming questions.
In the 1990s the early ideologues of globalization suggested the world has entered a perennial ‘end of history’ scenario of abundance and connectivity. Almost nobody believes that in 2020, but that is the least of it.
Instead what we might be facing is that the whole epoch of globalization was an ephemeral blip, and its inevitability an illusion, about to be swept away by the more powerful forces of epidemics, climate change, resource scarcity and the political turbulence and violence they generate.<br />
This is a possibility, not a certainty and even if things go that way, it should not be imagined in a binary fashion. It is tempting to connect various aspects of crisis situations into an overall ‘collapsitarian’ narrative and prophylactically fantasize about ‘collapse’ or ‘the event’, after which ‘it will be over’.
This is an emotional reaction of preventive despair, but in reality the global economy cannot just disappear overnight, as it has massive inertia, technology and vested interests backed up by state power on its side to keep it going.
It is possible, though by now difficult to see how, that the current epidemic will be brought under control before it infects say 10% of the global population and becomes endemic.
Similarly, by a massive interventionist turn (along the lines of a Green New Deal) to decarbonize the economic system and invest in carbon capture technologies and reforestation to sequester the CO2 already in the atmosphere global warming could still be slowed down, so it does not exceed 2C by 2100. For this <em>yearly</em> emission reductions of 5-10% would be needed, not a <em>growth</em> of emissions as it is happening currently.
Within a best case scenario of moderate warming, its effects could be mitigated by extensive urban planning (relocation), infrastructure (water) and health care investment, so they are not disproportionately concentrated in the geographic regions and social strata with the least resources. In this scenario a window of opportunity could still be open for new technologies to overcome resource constraints and globalization to continue apace on the way to a <a href="https://www.theguardian.com/books/2019/may/29/fully-automated-luxury-communism-aaron-bastani-review">post-scarcity society</a>. This passage is not completely barred, but, at the very least, seems a more and more unlikely best case scenario than a safe bet.</p>

<p>Suppose however that the best case scenario will not materialise and globalization, as we know it, is about to undergo some form of involution. The most immediate and disturbing question for those of us shaped and defined by this era is perhaps not even the usual ‘what do we do?’, but a more elementary one: if we cannot be citizens of the global village of eternal progress anymore, who are we going to be?</p>

<p><br /></p>

<p><strong>Notes</strong><br />
<a id="myfootnote1">(a)</a> GDP is a ‘flow’ measure: it’s a rate, not a stock, so this is not the cumulative amount of capital stock built up, but the level of economic activity per year. <a href="#fn1">↩</a><br />
<a id="myfootnote2">(b)</a> Additionally, in 1871 most ‘economic’ activity in the world was still outside the monetary economy so the estimate for world GDP, the denominator in the ratio, might be an underestimation, although I think Maddison etc. tried to account for this. <a href="#fn2">↩</a></p>]]></content><author><name></name></author><category term="political-economy" /><category term="globalization" /><category term="climate-change" /><category term="complex-systems" /><category term="ecology" /><category term="epidemics" /><category term="covid19" /><category term="growth" /><summary type="html"><![CDATA[Climate change, epidemics and political chaos might end globalization]]></summary></entry><entry><title type="html">Generating multistability by coupling self-activating genes</title><link href="http://localhost:4000/multistable/" rel="alternate" type="text/html" title="Generating multistability by coupling self-activating genes" /><published>2019-12-25T00:00:00+00:00</published><updated>2019-12-25T00:00:00+00:00</updated><id>http://localhost:4000/multistable</id><content type="html" xml:base="http://localhost:4000/multistable/"><![CDATA[<!---This [repository](https://github.com/mbkoltai/multistable_coupled_toggle) contains MATLAB scripts to model the stationary and dynamical behavior of --->
<p>In this post I want to explore how we can generate a regulatory system that has several (more than 2) fixed points by coupling self-activating genes. It is an expanded model of a <a href="https://www.nature.com/articles/35002131">toggle switch</a>: two genes (variables) that inhibit each other but also have nonlinear self-activation.
The <a href="https://github.com/mbkoltai/multistable_coupled_toggle">scripts I wrote in MATLAB</a> define a highly abstract, ordinary differential equation (ODE) model that does not describe stochastic fluctuations or the details of the underlying biochemical processes (transcription, translation, folding etc), as my interest here was to model multistable behavior in general.</p>

<p>My idea (coming from <a href="https://pubs.acs.org/doi/10.1021/jp403156m">this</a> paper) was that if the genes are bistable on their own then their nullclines can have 9 intersection points, ie. the two-dimensional systems when these genes are coupled can have up to 4 stable fixed points. Imagine two ‘S’ letters, one aligned with the \(x\) axis, the other with the \(y\) axis - how many times can they intersect?</p>

<p>In the main script <a href="https://github.com/mbkoltai/multistable_coupled_toggle/blob/master/multistable.m">multistable.m</a> we can first experiment with the parameters of a single self-activating gene: the cooperativity parameter (\(n\)), the threshold of activation (\(K\)) and the rate of basal activation (transcription/translation) of the gene (\(\mathbf{\beta}\)). The ODE for a single gene is:<br />
\(\frac{dx(t)}{dt} = \beta + \frac{x(t)^n}{x(t)^n + K^n} - x(t)
\tag{1}\label{ode_autoact}\)</p>

<p>While I am not assigning specific units to the variables and parameters, it is interesting to note what their dimensions are.<br />
The differential equation describes a <em>rate</em>, a change of concentration (mass per unit of volume) per unit of time, so it has to have a dimension of \(CT^{-1}\) (C: concentration, T: time).<br />
\(\beta\) also has dimension of \(CT^{-1}\). The state variable \(x(t)\) refers to the concentration of the gene product so its dimension is \(C\) (concentration) and \(K\) must have the same dimension.<br />
Then, strictly speaking the second term is dimensionless and would need to have a rate constant with dimension of \(CT^{-1}\) and the last term a rate constant with dimension of \(T^{-1}\).<br />
Since in practice these parameters only scale the production and degradation processes I am dropping them. This could be interpreted, if we are keen on dimensional consistency, as assuming their value is one, or that all other terms were divided by them.</p>

<p>We choose the values of these parameters as, for example:</p>
<pre><code class="language-MATLAB">k_val=3/4; % threshold (50% of maximal rate)
beta_vals = [0 1e-3 linspace(0.01,k_val,100)]; % range of values for basal rate
n_vals=[2:5 8 10]; % % range of values for cooperativity
</code></pre>

<p>We then run the calculation by calling the function <em>fcn_bistab_roots</em>:</p>
<pre><code class="language-MATLAB">[roots_real_nonnegat_matr,roots_all] = fcn_bistab_roots(beta_vals,n_vals,k_val);
</code></pre>

<p>Since I am solving here only for the stationary solution (steady state, fixed points) I am not numerically solving the ODE. Instead, within <em>fcn_bistab_roots</em>, I solve eq. \ref{ode_autoact} by setting the left hand side to 0 and rearranging the equation into polynomial form, which is:<br />
\(x (x^n + K^n) - \beta (x^n + K^n) - x^n = x^{n+1} - (1 + \beta) x^n + K^n x - \beta K^n = 0\)</p>

<p>\(x\) here stands for the stationary value of \(x(t)\).
I solve this polynomial with MATLAB’s root-finding algorithm \(root\).
There cannot be more than 3 real and nonnegative roots of this polynomial, these physically relevant roots are contained in the matrix <em>roots_real_nonnegat_matr</em> for the  parameter sets we generated.</p>

<p>I wrote two functions to visualize the solutions as a function of the basal production rate \(\beta\).
With <em>fcn_plot_bifurc_diff_n_heatmap</em> we can visualize the results as heatmaps on separate subplots for the different values of the nonlinearity (cooperativity) parameter \(n\):</p>

<pre><code class="language-MATLAB">fcn_plot_bifurc_diff_n_heatmap(beta_vals, n_vals, k_val, roots_real_nonnegat_matr)
</code></pre>

<p><img src="/images/bifurc_heatmaps_autostim.jpg" alt="_config.yml" />
<strong>Figure 1. Heatmaps showing the fixed points of a self-activating gene at different values of the cooperativity parameter. There are three bands corresponding to the three possible fixed points.</strong></p>

<p>Or as lineplots where the unstable fixed points are shown by the red dotted lines, called by the command:</p>
<pre><code class="language-MATLAB">fcn_plot_bifurc_diff_n(roots_real_nonnegat_matr, beta_vals, n_vals,k_val,plot_pars)
</code></pre>
<p>and producing these plots:
<img src="/images/bifurc_plots_autostim.jpg" alt="_config.yml" />
<strong>Figure 2. Bifurcation plots for a self-activating gene at different values of the cooperativity parameter. Blue lines are stable fixed points, dashed red lines are unstable.</strong></p>

<p>The lower threshold for the bistable range goes down while its extension grows with an increasing nonlinearity of the auto-activation.</p>

<p>Now, as it was shown by <a href="https://www.nature.com/articles/35002131">one of the first</a> landmark papers of <a href="http://vcp.med.harvard.edu/timeline.html">modern</a> (&gt;2000) systems biology how two genes mutually inhibiting each other can lead to bistable behavior if the inhibition has a nonlinear (sigmoidal effect).
In <a href="https://pubs.acs.org/doi/10.1021/jp403156m">this paper</a> it was pointed out that if the auto-activation of these two genes already makes them bistable then coupling them can generate several stable fixed points.</p>

<p>To intuitively illustrate this point, before setting up a model, let’s call the two genes A and B and we visualize their nullclines as a function of the value of the other gene.
Note that as we analyze the system in 2D now the basal production rate is a single value, we are not scanning through a range of values.
Where the two nullclines intersect we have a global fixed point: both variables have 0 time derivatives at these intersection points.</p>

<p><img src="/images/drawing_nullclines.png" alt="_config.yml" /></p>

<p><strong>Figure 3: Sketch of intersecting nullclines</strong></p>

<p>We can have up to 9 intersection points and 4 of them can be intersections of the stable branches of the nullclines, shown by the green circles, so these will be stable fixed points.</p>

<p>I implemented this two-dimensional system with adjustable parameters in MATLAB. First, I calculate the nullclines by polynomial root-finding.</p>

<p>The equations for the two genes are:<br />
\(\frac{dA}{dt} = \beta_A + f_A (1 + f_{BA}) - A\)<br />
\(\frac{dB}{dt} = \beta_B + f_B (1 + f_{AB}) - B\)</p>

<p>\(f_A\) and \(f_B\) are the self-activation functions, \(f_{BA}\) is the inhibition mechanism from \(B\) to \(A\) and \(f_{AB}\) vice versa. The basal production terms and the decay terms are as in eq. \ref{ode_autoact}.</p>

<p>Expanding the activation and inhibition functions the full equations are:<br />
\(\frac{dA}{dt} = \beta_A + \frac{A^n}{ A^n + k_{AA}^n } (1 + \frac{k_{BA}^n}{k_{BA}^n + B^n}) - A\)<br />
\(\frac{dB}{dt} = \beta_B + \frac{B^n}{ B^n + k_{BB}^n } (1 + \frac{k_{AB}^n}{k_{AB}^n + A^n} ) - B\)</p>

<p>Again, since we are (first) solving for the stationary solutions we can rearrange the equations to polynomial form and for each equation treat the other variable as a parameter to calculate the nullclines.
This is done by calling the function <em>fcn_nullclines_double_inhib</em>. We need to specify the range of values for the two variables where the nullclines are calculated and also the six parameters \([n,k_{AA},k_{BA},\beta_a,k_{BB},k_{AB},\beta_b]\).</p>

<pre><code class="language-MATLAB">n=4;
kAA=3/4; kBB=3/4;
beta_a=1/4; beta_b=1/4;
kBA=1/2; kAB=1/2;
params = [n,kAA,kBA,beta_a,kBB,kAB,beta_b];
maxval_B=2.25; logvals=logspace(-2,log10(maxval_B),200);
linvals=linspace(0.01,maxval_B,300);
B_vals=[0 linvals]; A_vals=[0 linvals];
[real_nonnegroots_f1,real_nonnegroots_f2] = fcn_nullclines_double_inhib(A_vals,B_vals,params);
</code></pre>

<p>Polynomial rootfinding is rather fast, for 200 input values, the calculation takes 35 seconds on my laptop (CPU @ 2.50GHz, 2 Cores).</p>

<p>Next we can visualize the nullclines and their intersections that are the fixed points of the model by the function <em>fcn_plot_double_inhib</em>:</p>
<pre><code class="language-MATLAB">parnames='$[n, k_{AA}, k_{BA},\beta_a, k_{BB},k_{AB},\beta_b]=$';
legend_str={'dA/dt=0,stable','dA/dt=0,unstable','dA/dt=0,stable'};
plot_pars={22,3,5,parnames,legend_str,0.02};
fcn_plot_double_inhib(B_vals,real_nonnegroots_f1,A_vals,...
    real_nonnegroots_f2,params,plot_pars,'vectorfield')
</code></pre>

<p>The flag ‘vectorfield’ tells the function to evaluate the algebraic equations that are the right-hand side of the differential equations showing the value of time-derivatives at that point of the coordinate system.</p>

<p>For a parameter set with basal production rates falling within the bistable region of the bifurcation plot on Figure 2 for \(n=4\) both variables have nullclines with 3 branches across the entire range.</p>

<p><img src="https://raw.githubusercontent.com/mbkoltai/mbkoltai.github.io/master/images/double_inhib_bistable_symm_vectorfield_n4.jpg" style="width:80%" alt="n4_vectorfield" />
<strong>Figure 4: Inhibition-coupled bistable genes, parameter set resulting in 4 stable fixed points.</strong> Green and blue lines showing the stable branches of the nullclines, dash-dotted thinner lines the unstable ones. Vector field showing the derivatives of the two state variables.</p>

<p>The stable branches are shown by thicker markers (green and blue) and the unstable ones by dashed-dotted thinner lines. The intersections of the stable branches have to be the fixed points of the system.<br />
It is interesting to visualize this as well and also the basins of attractions of the fixed points. To do this we numerically integrate the ODEs from a grid of initial conditions and store the solutions in the cell <em>trajectories</em>:</p>

<pre><code class="language-MATLAB">initvals=linspace(0,2.25,16); tspan=0:0.01:20; initvals_perms=permn(initvals,2);
options = odeset('RelTol',1e-4); % ,'AbsTol',at
trajectories=cell(1,size(initvals_perms,1));

for initv1=1:size(initvals_perms,1)
    disp(initv1/size(initvals_perms,1)); x0=initvals_perms(initv1,:);
    [t,x]=ode45(@(t,x)fcn_odes_double_inhib(t,x,params),tspan, x0);
    trajectories{initv1}=x;
end
</code></pre>

<p>For the parameter set above the trajectories look like this:</p>

<p><img src="/images/double_inhib_bistable_symm_manytrajs_n4.jpg" alt="_config.yml" />
<strong>Figure 5: Inhibition-coupled bistable genes: parameter set resulting in 4 stable fixed points.</strong>  Trajectories from different initial conditions converging to one of the four fixed points.</p>

<p>We can see how the unstable branches are the ‘frontiers’ of the basins of attraction.</p>

<p>An interesting case is a parameter set when the nullcline don’t just intersect at given points, but overlap along a whole section:</p>

<p><img src="/images/double_inhib_bistable_symm_trajs_n3_vectorfield.jpg" alt="_config.yml" />
<strong>Figure 6: Inhibition-coupled bistable genes, parameter set resulting in overlapping nullclines yielding fixed points along the overlapping section.</strong></p>

<p>In this case the overlapping section of the nullclines are all fixed points, so trajectories in the basin of attraction converge to different points of this line. This means (I think) there are infinitely many stable solutions that converge on the points of this line section in this region of the phase space. It would be interesting to explore what this means in terms of the polynomials.</p>

<p>An interesting question is what if we couple more than 2 bistable components. Would we get multistability with more than 4 fixed points? I might explore this question in a future post.</p>

<p>The script with its functions are available on <a href="https://github.com/mbkoltai/multistable_coupled_toggle">GitHub</a> and they can be downloaded and used in MATLAB.</p>

<!--- References
[1] [Gardner, T.S., Cantor, C.R. and Collins, J.J., 2000. Construction of a genetic toggle switch in Escherichia coli. Nature, 403(6767), p.339.](https://www.nature.com/articles/35002131)  
[2] [Lu, M., Jolly, M.K., Gomoto, R., Huang, B., Onuchic, J. and Ben-Jacob, E., 2013. Tristability in cancer-associated microRNA-TF chimera toggle switch. The journal of physical chemistry B, 117(42), pp.13164-13174](https://www.researchgate.net/publication/236913602_Tristability_in_Cancer_Associated_miRNA-TF_Chimera_Toggle_Switch)
--->]]></content><author><name></name></author><category term="systems-biology" /><category term="nonlinear-dynamics" /><category term="multistability" /><category term="kinetics" /><category term="complex-systems" /><summary type="html"><![CDATA[Fun with multistability (scripts+plots)]]></summary></entry><entry><title type="html">Exact solving of stochastic continuous-time logical models</title><link href="http://localhost:4000/exastolog/" rel="alternate" type="text/html" title="Exact solving of stochastic continuous-time logical models" /><published>2019-10-16T00:00:00+01:00</published><updated>2019-10-16T00:00:00+01:00</updated><id>http://localhost:4000/exastolog</id><content type="html" xml:base="http://localhost:4000/exastolog/"><![CDATA[<p>I recently submitted a manuscript that presents a calculation method to calculate the stationary solution of stochastic, continuous-time logical (Boolean) models.<br />
I adopted the mathematical technique from the field of chemical kinetics, specifically a number of articles from Jeremy Gunawardena and coauthors. These articles started with a small essay on the thresholding and switching properties of multisite (protein) phosphorylation <a href="https://www.pnas.org/content/102/41/14617">in PNAS</a> back in 2005 and then with a beautiful paper in Nature on ‘<a href="http://vcp.med.harvard.edu/papers/multistability.pdf">unlimited multistability</a>’ in 2009.</p>

<p>In these articles the results were still somewhat <em>ad hoc</em>, but they showed that the stationary solution of the kinetic equations describing post-translations modifications, which are nonlinear ordinary differential equations with bilinear terms complemented by some algebraic conservations, can be analytically obtained and that if we have multisite species there is no obvious limit to the number of stable steady states that these systems have.
Later on the results were generalized, culminating in the paper ‘<a href="http://vcp.med.harvard.edu/papers/jg-lap-dyn.pdf">Laplacian dynamics on general graphs</a>’ (2013) where they are most systematically summarized.</p>

<p>I was fascinated by these papers during my PhD. When I started to work on stochastic Boolean models with continuous time, that we simulated with Monte Carlo simulations (same way as Gillespie algorithm is used for stochastic kinetics) it occurred to me only after some time that if we want to have the stationary solution only then this is in fact identical to the problem described by Gunawardena, so his method can be adopted for the state transition graph of a logical model.<br />
The result from this work is now on <a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-03548-9">BMC Bioinformatics</a>.<br />
I’ve also implemented the calculations as a MATLAB toolbox that can be downloaded and used with the help of <a href="https://github.com/mbkoltai/exact-stoch-log-mod/tree/master/doc">this tutorial</a>.</p>]]></content><author><name></name></author><category term="cancer" /><category term="systems-biology" /><category term="kinetics" /><category term="tools" /><summary type="html"><![CDATA[By matrix method from kinetics]]></summary></entry><entry><title type="html">Dynamic behavior of sequentially determined values</title><link href="http://localhost:4000/seqvalues/" rel="alternate" type="text/html" title="Dynamic behavior of sequentially determined values" /><published>2019-03-02T00:00:00+00:00</published><updated>2019-03-02T00:00:00+00:00</updated><id>http://localhost:4000/seqvalues</id><content type="html" xml:base="http://localhost:4000/seqvalues/"><![CDATA[<p>In my <a href="https://mbkoltai.github.io/dynamic-prodprice-simplerepr/">previous post</a> I discussed a simple model of sequentially defined prices of production. These production prices for any good are defined as the good’s input cost (wages + non-labour costs) plus a markup equal to the rate of profit/surplus labor in the entire (two department) economy.
As I discussed this model eventually converges to a stationary solution that is identical of the algebraic system of equations with identical input and output prices, ie.
\(\mathbf{p} = \mathbf{p}(\mathbf{A} + w \mathbf{l})(1+r)
\tag{1}\label{simul_val}\)</p>

<p>The system of difference equations for (more than one) prices of production had a nonlinear term due to profit rate equalization, ie. redistribution of value produced in the different sectors:
\(\mathbf{p}_{t+1} = \mathbf{p}_t (\mathbf{A} + w \mathbf{l})
(1 + \frac{ \mathbf{l} \mathbf{X} - \mathbf{p}_t w \mathbf{l} \mathbf{X} }{ \mathbf{p}_t (\mathbf{A} + w \mathbf{l}) \mathbf{X} } ) =
\mathbf{p}_t (\mathbf{A} + w \mathbf{l}) \frac{ ( \mathbf{p}_t \mathbf{A} + \mathbf{l}) \mathbf{X} }{ \mathbf{p}_t (\mathbf{A} + w \mathbf{l}) \mathbf{X} }
\tag{2}\label{unit_price_dynam_explicit}\)</p>

<p>It is obvious that in the case of a model with only one good, so if \(A\), \(l\), \(X\) are scalars, not matrices/vectors, the nonlinearity drops out and the system simplifies to
\(p_{t+1} = p_t a + l\), that has an explicit solution, which is:</p>

<p>\(p_{t} = p_0 a^t + l \sum_{i=0}^{t-1} a^i = p_0 a^t  + \frac{l}{1-a} (1-a^t)\),</p>

<p>which for \(a&lt;1\) (meaning there is a physical surplus) converges to \(p^* = \frac{l}{1-a}\). In this case there is no redistribution of added value through prices of production, so value and price are the same, equaling to the price of inputs plus the incorporated labour.</p>

<p>Since it is more interesting to work with the more general case of multiple goods/sectors, but without the non-linearity, I will look at the dynamic behavior of values instead of prices of production, following an exchange between <a href="http://digamo.free.fr/dl2freeman.pdf">Duménil&amp;Lévy</a> (D&amp;L) and <a href="https://copejournal.com/wp-content/uploads/2015/12/Giussani-Dynamic-and-Static-Marxian-Values-A-Partial-Rejoinder-To-A-Rejoinder.pdf">P. Giussani</a> around 2000.</p>

<p>When I write the value of a particular good, I mean the value of its inputs plus the amount of (socially necessary) labour directly embodied in it, ie. using a sequential definition<br />
\(\Lambda_t = \mathbf{A} \Lambda_{t-1} + \mathbf{L}_t
\tag{3}\label{dynamic_values}\)</p>

<p>or in the simultaneous description (dropping time subscripts):</p>

\[\Lambda = \mathbf{A} \Lambda + \mathbf{L}
\tag{4}\label{simult_values}\]

<p>where again \(L\) is the column vector of labour values, \(A\) the input-output matrix, and \(\Lambda\) the column vector of unit values.</p>

<p>The solutions for the unit values are then for simultaneous values:</p>

\[\Lambda = (\mathbf{I} - \mathbf{A})^{-1} \mathbf{L}
\tag{5}\label{simult_values_sol}\]

<p>and sequentially determined values:</p>

\[\Lambda_t = \mathbf{A}^{t} \Lambda_0 + (\mathbf{I} - \mathbf{A})^{-1} (\mathbf{I} - \mathbf{A}^{t} ) \mathbf{L}
\tag{6}\label{dynamic_values_sol}\]

<p>Since it is assumed (elements of) \(A&lt;1\) (otherwise we would have shrinking reproduction), therefore \(\lim\limits_{t \to \infty}\Lambda_t = \Lambda^{* } = (I-A)^{-1} L\), same as the simultaneous equation \ref{simult_values_sol}.
For this reason it was argued by <a href="http://www.countdownnet.net/Allegati/53%20The%20so-called%20Temporal%20Single%20System%20%28TSS%29%20the%20so-called%20Standard%20Simultaneous%20Methodology%20%28SSM%29%20and%20the%20correct%20definition%20of%20labour%20values.pdf">Stamatis 1999</a> that the sequential formalism is simply an iterative calculation procedure to solve the algebraic equation of \ref{simult_values_sol}, and not a model of economic dynamics. I will address this question later, first I will explore some dynamic properties of this formalism, independent of its interpretation.</p>

<p>It was pointed out by D&amp;L that in the sequential formalism it is possible to have growing labour productivity (falling labour inputs per unit of goods) with <em>growing</em> unit values.
Specifically, if instead of a constant \(L\), it is now a function of time:</p>

<p>\(L_t = \alpha + \beta \gamma^t\),</p>

<p>with \(0&lt;\gamma&lt;1\), that is \(L\) will be monotonically decreasing with time, falling to \(\alpha\) eventually (the coefficients are column vectors).</p>

<p>The explicit solution for sequential values is then:</p>

\[\Lambda_t =
A^t \Lambda_0 + (I - A)^{-1} (I-A^t) \mathbf{\alpha} + (A - \gamma I)^{-1} (A^t - \gamma^t I) \mathbf{\beta}
\tag{7}\label{dynamic_values_sol_L_t}\]

<p>if \(\gamma\) is a scalar, otherwise the last term is \((A^t - \left&lt; \gamma^t \right&gt; I ) \beta\), with \(\left&lt; \gamma \right&gt;\) being the diagonal matrix from \(\gamma\).
Since the \(A^t\) and \(\gamma^t\) terms are shrinking to zero with time, the equilibrium solution is:</p>

<p>\(\Lambda^{* } = (I-A)^{-1} \mathbf{\alpha}\),</p>

<p>again the same as in the simultaneous description.</p>

<p>D&amp;L point out that if the initial value \(\Lambda_0 &lt; \Lambda^{* }\), then \(\Lambda^{t}\) will rise, converging to the equilibrium from below, even though the labour content is falling. D&amp;L refer to this as a ‘productivity paradox’.
In fact, the behavior of sequential values is even more complex.
In equation \ref{dynamic_values_sol_L_t} there are exponential terms both in \(A\) and \(\gamma\) suggesting the behavior can be non-monotonic. This is in fact what happens with certain parameter sets as shown by the numerical examples below.</p>

<p>The parameter set used was: \(\mathbf{\alpha}= [0.2; 0.4], \mathbf{\beta}= [0.3; 0.1],
\mathbf{\gamma}= [0.9; 0.8],
\mathbf{A} = \begin{bmatrix} 2/3 &amp; 1/3 \\ 1/6 &amp; 1/2 \\ \end{bmatrix}\)</p>

<p><img src="/images/unitprices_nonmonot_paradox.png" alt="_config.yml" />
<strong>Figure 1: Non-monotonic dynamics of sequential values with increasing productivity</strong></p>

<p>This non-trivial and somewhat puzzling feature comes about because of two dynamical terms that can be seen in  equation \ref{dynamic_values_sol_L_t}: one coming from the input values of the previous period and the other from labor productivity.
If the initial input values are far from the stationary value (of the <em>simultaneous equations</em> with that level of productivity) then it can take several iterations until the falling labor content becomes the dominant term, and this can result in non-monotonic behavior.</p>

<p>For the one-good case, it is easier to see the conditions for this. In this case the difference \(\epsilon\) between any two consecutive steps is:</p>

\[\epsilon = \left(\lambda_0 - \frac{\alpha}{1-a} + \frac{\beta}{a-\gamma} \right) a^t \left(1-\frac{1}{a} \right) +
\left(- \frac{\beta}{a - \gamma} \right) \gamma^t \left(1-\frac{1}{\gamma} \right)\]

<p>Denoting the difference between the initial and stationary value \(\Delta = \lambda_0 - \frac{\alpha}{1-a}\), and after some rearrangements, the condition for non-monotonic behavior is:</p>

<ul>
  <li>
    <p>\(\Delta &lt; \frac{\beta}{a-\gamma} \left( \frac{\gamma}{a}^{t-1} \frac{\gamma-1}{a-1} -1 \right)\), if \(\Delta &gt;0\) (increasing unit values for \(\lambda_0 &gt; \lambda^*\))</p>
  </li>
  <li>
    <p>\(\Delta &gt; \frac{\beta}{a-\gamma} \left( \frac{\gamma}{a}^{t-1} \frac{\gamma-1}{a-1} -1 \right)\), if \(\Delta &lt; 0\) (decreasing unit values for \(\lambda_0 &lt; \lambda^*\))</p>
  </li>
</ul>

<p>As the numerical example above shows this can be satisfied in both cases.</p>

<p>Is this behavior of sequential values «paradoxical»?
No matter how we answer this question, it certainly would be an exaggeration to claim that what we see here is - even an extremely simplified - model of economic dynamics.
The technical coefficients of the system are defined independently from values, there are no feedback effects, and yet the system shows relatively complicated dynamic behavior already, depending on its initial value. This is not due to endogenous technical change or of disequilibrium between supply and demand, but simply to the dependence on the previous state.</p>

<p>Yet this can also be seen as an interesting feature of the sequential model, in contrast to the simultaneous one, namely that the periods are connected: the output price/value of one period is the input of the next. This suggests that it can be used in a dynamical model of the <a href="https://www.sciencedirect.com/science/article/pii/0022053182900631">circuit(s) of capital</a>.
If we have only one circuit per sector like above, this assumes that all capitals in that sector are synchronized, which is clearly not the case in reality.
But if they are not synchronized, the formalism would have to be more complex. When one circuit of capital is in the phase of production others are releasing new products to the market, which can devalue the inputs.
Therefore the value of inputs would not equal their original value, but would be - intuitively - some weighted average of past values of the inputs used by the individual circuits.
In my next posts I want to address this question of connecting a model of the circuit of capital with these different methods of value calculation.</p>]]></content><author><name></name></author><category term="political-economy" /><category term="economic-models" /><category term="classical-political-economy" /><category term="marxian-economics" /><category term="transformation-problem" /><summary type="html"><![CDATA[Weird properties of dynamic labor values]]></summary></entry><entry><title type="html">A toy model of dynamic prices of production</title><link href="http://localhost:4000/dynamic-prodprice-simplerepr/" rel="alternate" type="text/html" title="A toy model of dynamic prices of production" /><published>2019-01-12T00:00:00+00:00</published><updated>2019-01-12T00:00:00+00:00</updated><id>http://localhost:4000/dynamic-prodprice-simplerepr</id><content type="html" xml:base="http://localhost:4000/dynamic-prodprice-simplerepr/"><![CDATA[<p>I have not posted lately on A. Trigg’s book on reproduction schemas as I got into reading on the (in)famous ‘transformation problem’ and could not resist playing with some models in the literature. In one sentence the transformation problem is about whether the claim that the value of commodities is indirectly or directly determined by the average labour time needed for their production (+ non-labour inputs) is compatible with the observation/expectation that profit rates across sectors with different labour/capital ratios would tend toward equalization. I will not discuss this problem per se in this post, there is a lot of literature available on that, although this model can be regarded as a solution to the ‘transformation problem’.
I want to write down the equations of a dynamical model proposed in Kliman [1988] with numerical examples (but without the equations explicitly), of prices of production where the aggregate equalities (total price) = (total value) and (total surplus value) = (total profit) are satisfied, total supply can be sold in each period of production, and the balancing condition (see Eq. \eqref{balancing_cond}) between the two sectors of the economy is also met.
The model has the following assumptions and properties:<br />
1) value is expressed in money, there is only one accounting system<br />
2) non-labor inputs transfer their value to the products they are used up for, but no more or less<br />
3) a given amount of labor adds the same amount of value, profit can therefore originate only from unpaid (surplus) labour: less is paid for wages than the amount of new value added by labour, the difference between the two appears as profit (for the entire economy, not for an individual sector)<br />
4) the system shows <a href="https://mbkoltai.github.io/reprod_multipl2/">simple reproduction</a> only: it is producing the same physical amounts of goods in each period, and the physical surplus (output minus inputs used up) takes the form of consumption goods only and it is consumed in each period instead of being redirected (accumulated) into the system as new capital goods or new consumption goods for an expanding workforce. The amount of non-labour inputs (constant capital) and work performed do not change.<br />
5) the real wage is kept constant: the wage paid for workers enables them to buy the same amounts of consumption goods. The nominal wage can however change if the unit price of consumption goods change.<br />
6) Profit rates are equalized</p>

<p>Of course assumptions no. 2-3 can be (are) contested, and the idea that human labour is the only source of new value and therefore of profit can be rejected, but this - ie. the validity of the labour theory of value - is a topic for another post. Assumption no. <em>4-5</em> are just convenient first assumptions, but the system can be changed to expanded reproduction etc. by altering its coefficients.
Assumption <em>6</em> is reasonable as a tendency (capital flows in search of (sectors with) higher rates of return) but one should also have a mechanism implemented in a more serious model.
My goal here is just to build a small mathematical model that is internally consistent and has a dynamics that can later be made more realistic by introducing more detail. As the system is dynamic  prices and profit rates can change, which is a precondition to incorporate crises in the model.</p>

<p>Like in the input-output models I <a href="https://mbkoltai.github.io/reprod_multipl2/">discussed previously</a> we have two economic sectors (or departments), the first (\(D_1\)) producing capital goods (this could be raw materials as well, any non-labour inputs used up in production), the second (\(D_2\)) consumption goods (<em>CoG</em>). Since we are dealing with simple reproduction and we will also abstract from fixed capital, therefore all capital goods are used up in each period of production, the total use of capital goods has to equal the total output (\(W_1\)) of \(D_1\).
This gives us the equality
\(W_1 = C_1 + V_1 + S_1 = C_1 + C_2\), or,<br />
\(C_2 = V_1 + S_1
\tag{1}\label{balancing_cond}\)
In other words, the exchanges between the two departments (wages + profits in <em>D1</em> = value of constant capital used up in <em>D2</em>) have to be equal.</p>

<p>In one important respect the current model will be different from the one discussed in the case of input-output tables and this will change the meaning of the equality of Equation \eqref{balancing_cond}. In the input-output description it is assumed (this assumption can be called ‘simultaneous valuation’) that unit prices for the two goods have to be the same when they enter as inputs and when they emerge as outputs in a given period of production.
Since unit prices cannot change what the system describes are the relative prices required to solve the system of algebraic equations that describe the input-output equalities. A uniform profit rate is normally assumed, which gives one more constraint for the price system, but since there is one more unknown than the number of equations, only relative prices can be calculated.
The input-output model as usually understood is then a model of equilibrium prices for given technical (input-output) coefficients and a level of real wage (units of <em>CoG</em> paid for a unit of labour performed). In fact, because of the fact that input and output prices are the same and that profit rates are equal across sectors, both prices and the rate of profit are determined by the technical coefficients and the real wage rate (which is also a physical quantity), and in a sense prices become irrelevant (see <a href="https://www.tandfonline.com/doi/pdf/10.1080/095382599107165">Kliman (1999)</a>).<br />
In contrast, in the model I will discuss here this assumption of the equality of input and output unit prices is dropped: input prices determine output prices sequentially. Consequently, instead of a system of algebraic equations with the same unit prices on both the right and left side, we will have a system of difference equations, that we need to provide with initial values in the first period of reproduction. In periods <em>t&gt;1</em> the input prices are given by the output prices of the preceding period.</p>

<p>To summarise, in the simultaneous description we have unit prices as:
\(\mathbf{p} = \mathbf{p}(\mathbf{A} + w \mathbf{l})(1+r)
\tag{2}\label{simul_val}\)</p>

<p>where \(\mathbf{p}\) is the row vector of unit prices, \(\mathbf{A}\) the input-output matrix, \(w\) is the wage rate, \(\mathbf{l}\) is the row vector of labour inputs (quantities) per unit of output of each commodity and \(r\) is the profit rate. \(\mathbf{A}\), \(w\) and \(l\) are given, whereas \(\mathbf{p}\) and \(r\) are the unknowns.
Defining the ‘augmented’ input matrix \(\mathbf{M} = A + w l\), we can write the profit rate \(r = (pX - pMX)/pMX\), where X is the column vector of gross outputs (physical quantities), but this is not an independent equation but rather comes from \(\mathbf{p X} = (\mathbf{p} \mathbf{M} (1+r))\mathbf{X}\), so although \(r\) can be calculated (given \(\mathbf{M}\)), but for production prices \(\mathbf{p}\) we will only have the relative prices, as any set of absolute prices with the same ratios will satisfy the equations.</p>

<p>In the dynamic description we have instead:
\(\mathbf{p}_{t+1} = \mathbf{p}_t(\mathbf{A} + w \mathbf{l})(1+r)
\tag{3}\label{dynamic unit prices}\)
which is a system of difference equations, not algebraic ones. Here, the input unit prices are a given, they are data, and they are mapped onto the output prices by the technical coefficients, the wage rate and the markup of the aggregate profit rate. Moreover, because of the third assumption above, the profit rate can now be independently determined from the input unit prices, technical coefficients, the wage rate and the amount of labour performed:
\(r_{t,t+1} = (\mathbf{l}\mathbf{X} - \mathbf{p}_t w \mathbf{l} \mathbf{X})/
(\mathbf{p}_t (\mathbf{A} + w \mathbf{l}) \mathbf{X})
\tag{4}\label{profit_rate_dynamic}\)</p>

<p>Profit is the total amount of new value added minus the real wage of workers (quantity of consumption goods times their input unit price).
The rate of profit is given by dividing the amount of profit by total input costs that are also defined by technical coefficients, the wage rate and the input prices. It can be seen that the calculation of the profit rate only involves the input data of input prices and the coefficients, therefore it comes first. The calculation of unit output prices follows after, since they are the function of both the profit rate and input prices as can be seen from Equation \eqref{dynamic unit prices}.</p>

<p>Now let us go back to the equality of simple reproduction in Equation \eqref{balancing_cond}:<br />
\(C_2 = V_1 + S_1\) (coming from \(W_1 = C_1 + C_2\), \(W_i\) being gross output of a sector)<br />
In the equilibrium description of input-output tables, where input and output unit prices are equal, this equality is a relation between the inputs and outputs of the same period. As this is a description of equilibrium for a given set of technical and wage coefficients, there is in fact only one period, if we take another set of coefficients then we need to calculate another set of equilibrium prices.
But in the dynamic description this balancing condition is across two periods: the output of one period is the input of the next. In price terms, the output of capital goods has to equal the input of capital goods in the <em>next</em> period. In physical terms, since it is simple reproduction, it is also true that the inputs (of one good) used up in the current period has to equal the output (of the same good) of the current period. But in terms of money the current period’s output is the input of the <em>next</em> one, and it does not need to equal the input of this period, <em>unless</em> the difference equations for unit prices have reached their stationary value. So the equality in the dynamic setting will be:
\(W_1(t) = C_1(t+1) + C_2(t+1)\).</p>

<p>Let us write the dynamic equations for the unit prices in a form that they contain no other time-dependent variables, but only constants. All other variables of the system are governed by the unit prices as follows (from now on I put the time index in parenthesis instead of a subscript, as I use subscripts for department indices):</p>
<ul>
  <li>constant capital: \(C_1(t) = \alpha X_1 p_1(t)\), \(C_2(t) = (1-\alpha) X_1 p_1(t)\), since the total physical amount and sectoral distribution of capital goods do not change</li>
  <li>wages: \(V_1(t) = \beta_1 X_2 p_2(t)\), \(V_2(t) = \beta_2 X_2 p_2(t)\), since the real wage is defined as a fixed amount (\(\beta_1\), \(\beta_2\)) of consumption goods (\(X_2\)) that the wages can buy, and distribution of the workforce does not change</li>
  <li>revenue: \(m(t)=\mu X_2 p_2(t)\), profit spent on consumption goods by capitalists, also kept constant in physical terms (\(\mu X_2\), and \(\mu + \beta_1 + \beta_2 = 1\))</li>
  <li>total (gross) output: \(W_i(t) = p_i(t) X_i\)</li>
  <li>cost: \(K_1(t) = C_1(t) + V_1(t) = \alpha X_1 p_1(t) + \beta_1 X_2 p_2(t)\), \(K_2(t) = (1-\alpha) X_1 p_1(t) + \beta_2 X_2 p_2(t)\)</li>
  <li>profit rate: \(r(t) = \frac{L_T - (V_1(t)+V_2(t)) }{ K_1(t) + K_2(T)} = \frac{L_T - (\beta_1 + \beta_2) X_2 p_2(t)}{ p_1(t) X_1 + (\beta_1 + \beta_2) X_2 p_2(t) }\) (\(L_T\) is total labour performed)</li>
</ul>

<p>Since the output price of the current period is the input of the next period, and gross output is equal to input costs and a markup equal to the aggregate profit rate, we have:
\(p_i(t+1) X_i = W_i(t) = (C_i(t) + V_i(t)) (1 + r(t))
\tag{5}\label{unit_price_dynam_implicit}\)</p>

<p>Dividing by \(X_i\) and substituting the expressions listed above we have:<br />
\(\begin{bmatrix} p_1(t+1) \\ p_2(t+1 )\\ \end{bmatrix} = \begin{bmatrix} \alpha &amp; \beta_1 X_2 / X_1\\ (1 - \alpha) X_1 / X_2 &amp; \beta_2 \\ \end{bmatrix} \begin{bmatrix} p_1(t) \\ p_2(t)\\ \end{bmatrix} \frac{ p_1(t) + L_T/X_1 }{ p_1(t) + (\beta_1 + \beta_2) X_2/X_1 p_2(t) }
\tag{6}\label{unit_price_dynam_explicit}\)</p>

<p>This is a system of first-order, non-linear, autonomous difference equations, that - I think - cannot be solved analytically (so that \(p(t)\) would be a function of time and parameters only), but it is easy to simulate numerically, or solve for its fixed point (in which case it becomes a quadratic equation, with one positive solution).</p>

<p>I simulated the system in MATLAB with the following numerical values (also used in the article cited below as a reference): \(L_T = 300\), \(\alpha = 1/2\), \(\beta_1 = 1/6\), \(\beta_2 = 1/3\), \(\mu = 1/2\), \(X_1 = 200\), \(X_2 = 300\) and the initial values \(p_1(0)=p_2(0)=1\).
This is the plot of the dynamics of unit prices and some of the ratios of the system:</p>

<p><img src="/images/unitprices_ratios.png" alt="_config.yml" /></p>

<p>The system satisfies the following equalities (these are all in price terms):</p>
<ul>
  <li>\(W_1(t) = C_1(t+1) + C_2(t+1) = p_1(t+1) X_1\), output of capital goods of the current period equals input of capital goods in next period</li>
  <li>\(m_1(t) + V_1(t) = C_2(t)\), exchanges between the sectors have to balance (capitalist consumption + wage outlays from \(D_1\) equals outlays on capital goods from \(D_2\), with the other transactions being within the two departments)</li>
  <li>\(W_2(t) = V_1(t+1) + V_2(t+1) + m(t+1) = p_2(t+1) X_2\), output of consumption goods in current period equals outlay on wages plus consumption from profit (revenue) in next period</li>
  <li>\(\sum m_i(t) = \sum W_i(t-1) - \sum K_i(t)\), total revenue, ie. profit that can be spent on consumption equals the difference between the output of the previous period minus outlays on wages and capital goods in the current period</li>
</ul>

<p>Since unit prices are changing until we reach the stationary state, the amount of money needed for total outlays (wages + capital goods) is also changing (see on the plot above the ratio of costs), and since inputs (in this model) transfer their prices to the output, gross output in terms of price is also changing, though net value added does not. Once we reach the fixed point unit prices do not change anymore, therefore wages, profit, outlays on capital goods and gross output have also reached a stationary state. This final state is identical to the equilibrium price (equal input and output prices) solution to the system. The fixed point is obviously attracting, so sampling in initial values (for unit prices) will lead to the same stationary values, as shown in the plot below.</p>

<p><img src="/images/prices_prod_initval_sampling.png" alt="_config.yml" /></p>

<p>But the dynamical system converges to this stationary state only because the technical coefficients, the physical productivity and relative sizes of the departments do not change in this model.
If the parameters change before the system converges to the fixed point, then the pre-equilibrium behavior will continue (see Giussani 1991).
This simple model satisfies the requirements of a labour theory of value that total profit equals total surplus (unpaid) labour, total price equals total value, and the sectoral balances of simple reproduction are also respected, although this is enforced by the assumptions of the model that I’ll mention below. The unit prices of the two goods are different from their values, so it is only through aggregate quantities that prices are determined by labour values.</p>

<p>If we want to add additional detail to the model, the first thing to add should probably be growing labour productivity that would also mean expanded reproduction, so that some of the surplus is recycled to the system and not consumed. The other component to add for a bit more realistic model is fixed capital. If we add these, then it can start to make sense to ask questions on how productivity growth will affect profitability.</p>

<p>There are several potential problems with this model. First is how can we know the amount of value a unit of labour adds or represents, and the assumption that this amount (the ‘monetary expression of labour time’) does not change.
The second is that non-labour inputs (there is only one type in this model, ‘capital goods’ in general) transfer the value that they were bought at, but what happens if due to changes in productivity the inputs are worth less when the production period comes to its end, than at their time of purchase, what amount of value would they transfer?
Third, nominal wages automatically adjust to the new price of wage goods, as wages are defined as a fixed physical amount of wage goods times the output price of the previous period, assuming perfect adjustment of wages to match the supply of wage goods.
Finally, since the price of total output is growing, there needs to be more money in the system then in the first round (with the coefficients and the initial values used above), so the money supply would have to expand. I will return to these problems in future posts.</p>

<h3 id="script">Script</h3>

<p><a href="https://github.com/mbkoltai/mbkoltai.github.io/blob/master/images/sequential_prices.m">MATLAB script</a></p>

<h3 id="references">References</h3>

<p><a href="https://www.jstor.org/stable/40470553">Giussani: The Determination of Prices of Production, International Journal of Political Economy, Volume 21, 1991</a><br />
<a href="https://journals.sagepub.com/doi/10.1177/030981688803500106">Kliman, McGlone: The transformation non-problem and the non-transformation problem, Capital &amp; Class, Vol 12, Issue 2, 1988</a><br />
<a href="https://www.tandfonline.com/doi/pdf/10.1080/095382599107165">Kliman, McGlone: A Temporal Single-system Interpretation of Marx’s Value Theory, Review of Political Economy, Volume 11, Number 1, 1999</a></p>]]></content><author><name></name></author><category term="political-economy" /><category term="economic-models" /><category term="classical-political-economy" /><category term="marxian-economics" /><category term="transformation-problem" /><category term="nonlinear-dynamics" /><summary type="html"><![CDATA[With labor values and equilibrium]]></summary></entry></feed>